{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wibOiurwOvJ2"
      },
      "source": [
        "# Byte-Pair Encoding tokenization\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR3IDbrSOvJ3"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oRKl4h0DOvJ3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also log into Hugging Face."
      ],
      "metadata": {
        "id": "ZWx7SH7yO-uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "YMKP74wpPCGP",
        "outputId": "e4474c45-b9ff-4db3-8add-215853516c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "bb565bcf42a9496a8ddcb5714381a5f5",
            "2ae6d5bba7e142cdae5394d4fba9c780",
            "544784fb87a547bca297b28dbb277a7c",
            "92c7c7473ae34ab684846ac93993dd8a",
            "658930b52bd548a7bd2efe211839e170",
            "79761247e44348acb3ee2423f9853504",
            "2e407ef96ca04ecf9a9e8429c44a874a",
            "5a7048c7e1f54252866c2d08b844abfb",
            "3788ee0c347f450ab9f91978b5fb32de",
            "52cba522632145a1beeea62d570a8b14",
            "4961df58c64d45d5aad6d31fa1c2b57e",
            "35b79a4c8e6941598e7ea2047fd04ccc",
            "56988d3d867447bf83f6c2bd3d16173f",
            "007767878d374b9e9a5e19674e575619",
            "8217b552968e407eab876521e0c86ec3",
            "98dd185e7aba44108b4da18c7a3e7c22",
            "39736bf4168c493fa50e644c1091c604",
            "0033292f5d27416087cd09cffb0cd79b",
            "5cca24d5e7f246c6b7c45e1e35dbdf69",
            "02e4827c9e324653b8dea564dcb9c143"
          ]
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb565bcf42a9496a8ddcb5714381a5f5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Byte-Pair Encoding (<font color='blue'>BPE</font>) was initially developed as an algorithm to <font color='blue'>compress texts</font>, and then used by <font color='blue'>OpenAI</font> for <font color='blue'>tokenization</font> when <font color='blue'>pretraining</font> the <font color='blue'>GPT</font> model. It's used by a lot of Transformer models, including GPT, GPT-2, RoBERTa, BART, and DeBERTa."
      ],
      "metadata": {
        "id": "rGSOD5xQPBb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training algorithm\n",
        "\n",
        "BPE training <font color='blue'>starts</font> by <font color='blue'>computing</font> the <font color='blue'>unique set</font> of <font color='blue'>words</font> used in the <font color='blue'>corpus</font> (after the normalization and pre-tokenization steps are completed), then <font color='blue'>building</font> the <font color='blue'>vocabulary</font> by taking all the <font color='blue'>symbols</font> used to <font color='blue'>write</font> those <font color='blue'>words</font>. As an example, let's say our corpus uses these five words:\n",
        "\n",
        "```\n",
        "\"hug\", \"pug\", \"pun\", \"bun\", \"hugs\"\n",
        "```\n",
        "\n",
        "The base vocabulary will then be `[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\"]`. For <font color='blue'>real-world</font> cases, that <font color='blue'>base vocabulary</font> will contain all the <font color='blue'>ASCII</font> characters, at the very least, and probably some <font color='blue'>Unicode</font> characters as well. If an example you are tokenizing uses a <font color='blue'>character</font> that is <font color='blue'>not</font> in the <font color='blue'>training corpus</font>, that character will be <font color='blue'>converted</font> to the <font color='blue'>unknown token</font>. That's one reason why lots of NLP models are very bad at analyzing content with emojis, for instance.\n",
        "\n",
        "<Tip>\n",
        "\n",
        "💡The GPT-2 and RoBERTa tokenizers (which are pretty similar) have a clever way to deal with this: they <font color='blue'>don't look</font> at <font color='blue'>words</font> as being written with <font color='blue'>Unicode characters</font>, but with <font color='blue'>bytes</font>. This way the <font color='blue'>base vocabulary</font> has a <font color='blue'>small size</font> (256), but <font color='blue'>every character</font> you can think of will still be included and <font color='blue'>not</font> end up being <font color='blue'>converted</font> to the <font color='blue'>unknown token</font>. This trick is called <font color='blue'>byte-level BPE</font>.\n",
        "\n",
        "</Tip>\n",
        "\n",
        "After getting this <font color='blue'>base vocabulary</font>, we add new tokens until the desired vocabulary size is reached by learning <font color='blue'>merges</font>, which are <font color='blue'>rules</font> to <font color='blue'>merge two elements</font> of the existing vocabulary together into a new one. So, at the beginning these merges will <font color='blue'>create tokens</font> with <font color='blue'>two characters</font>, and then, as training progresses, longer subwords.\n",
        "\n",
        "At any step during the tokenizer training, the BPE algorithm will search for the <font color='blue'>most frequent pair</font> of <font color='blue'>existing tokens</font> (by \"pair,\" here we mean <font color='blue'>two consecutive tokens</font> in a word). That <font color='blue'>most frequent pair</font> is the one that will be <font color='blue'>merged</font>, and we rinse and repeat for the next step.\n",
        "\n",
        "Going back to our previous example, let's assume the words had the following frequencies:\n",
        "\n",
        "```\n",
        "(\"hug\", 10), (\"pug\", 5), (\"pun\", 12), (\"bun\", 4), (\"hugs\", 5)\n",
        "```\n",
        "\n",
        "meaning `\"hug\"` was present 10 times in the corpus, `\"pug\"` 5 times, `\"pun\"` 12 times, `\"bun\"` 4 times, and `\"hugs\"` 5 times. We start the training by <font color='blue'>splitting</font> each <font color='blue'>word</font> into <font color='blue'>characters</font> (the ones that form our initial vocabulary) so we can see each word as a list of tokens:\n",
        "\n",
        "```\n",
        "(\"h\" \"u\" \"g\", 10), (\"p\" \"u\" \"g\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"u\" \"g\" \"s\", 5)\n",
        "```\n",
        "\n",
        "Then we look at pairs. The pair `(\"h\", \"u\")` is present in the words `\"hug\"` and `\"hugs\"`, so 15 times total in the corpus. It's not the most frequent pair, though: that honor belongs to <font color='blue'>`(\"u\", \"g\")`</font>, which is present in `\"hug\"`, `\"pug\"`, and `\"hugs\"`, for a grand total of <font color='blue'>20 times</font> in the vocabulary.\n",
        "\n",
        "Thus, the <font color='blue'>first merge rule</font> learned by the <font color='blue'>tokenizer</font> is <font color='blue'>`(\"u\", \"g\") -> \"ug\"`</font>, which means that `\"ug\"` will be <font color='blue'>added</font> to the <font color='blue'>vocabulary</font>, and the <font color='blue'>pair</font> should be <font color='blue'>merged</font> in <font color='blue'>all</font> the <font color='blue'>words</font> of the <font color='blue'>corpus</font>. At the end of this stage, the vocabulary and corpus look like this:\n",
        "\n",
        "```\n",
        "Vocabulary: [\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\"]\n",
        "Corpus: (\"h\" \"ug\", 10), (\"p\" \"ug\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"ug\" \"s\", 5)\n",
        "```\n",
        "\n",
        "Now we have some pairs that result in a <font color='blue'>token longer</font> than <font color='blue'>two characters</font>: the pair <font color='blue'>`(\"h\", \"ug\")`</font>, for instance (present 15 times in the corpus). The most frequent pair at this stage is `(\"u\", \"n\")`, however, present 16 times in the corpus, so the <font color='blue'>second merge rule</font> learned is <font color='blue'>`(\"u\", \"n\") -> \"un\"`</font>. Adding that to the vocabulary and merging all existing occurrences leads us to:\n",
        "\n",
        "```\n",
        "Vocabulary: [\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\", \"un\"]\n",
        "Corpus: (\"h\" \"ug\", 10), (\"p\" \"ug\", 5), (\"p\" \"un\", 12), (\"b\" \"un\", 4), (\"h\" \"ug\" \"s\", 5)\n",
        "```\n",
        "\n",
        "Now the most frequent pair is <font color='blue'>`(\"h\", \"ug\")`</font>, so we learn the merge rule <font color='blue'>`(\"h\", \"ug\") -> \"hug\"`</font>, which gives us our first <font color='blue'>three-letter token</font>. After the merge, the corpus looks like this:\n",
        "\n",
        "```\n",
        "Vocabulary: [\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\", \"un\", \"hug\"]\n",
        "Corpus: (\"hug\", 10), (\"p\" \"ug\", 5), (\"p\" \"un\", 12), (\"b\" \"un\", 4), (\"hug\" \"s\", 5)\n",
        "```\n",
        "\n",
        "And we continue like this until we reach the desired vocabulary size.\n",
        "\n",
        "<Tip>\n",
        "\n",
        "✏️ **Now your turn!** What do you think the next merge rule will be?\n",
        "\n",
        "</Tip>"
      ],
      "metadata": {
        "id": "bUkDomObPOis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The current state of the corpus after the previous merges is:\n",
        "\n",
        "```\n",
        "Vocabulary: [\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\", \"un\"]\n",
        "Corpus: (\"h\" \"ug\", 10), (\"p\" \"ug\", 5), (\"p\" \"un\", 12), (\"b\" \"un\", 4), (\"h\" \"ug\" \"s\", 5)\n",
        "```\n",
        "\n",
        "We need to identify all the <font color='blue'>pairs</font> and count their <font color='blue'>frequencies</font>:\n",
        "\n",
        "*  (\"p\", \"ug\"): appears in \"pug\" (5 times) = 5 times\n",
        "*  (\"p\", \"un\"): appears in \"pun\" (12 times) = 12 times\n",
        "*  (\"b\", \"un\"): appears in \"bun\" (4 times) = 4 times\n",
        "*  (\"hug\", \"s\"): appears in \"hugs\" (5 times) = 5 times\n",
        "\n",
        "The <font color='blue'>most frequent pair</font> is <font color='blue'>(\"p\", \"un\")</font> with <font color='blue'>12 occurrences</font>.\n",
        "Therefore, the <font color='blue'>next merge rule</font> will be <font color='blue'>(\"p\", \"un\") -> \"pun\"</font>. This will <font color='blue'>add \"pun\"</font> to the <font color='blue'>vocabulary</font> and <font color='blue'>merge</font> all occurrences of the pair <font color='blue'>(\"p\", \"un\")</font> in the <font color='blue'>corpus</font>. After this merge, the current state of the corpus is:\n",
        "\n",
        "```\n",
        "Vocabulary: [\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\", \"un\", \"hug\", \"pun\"]\n",
        "Corpus: (\"hug\", 10), (\"p\" \"ug\", 5), (\"pun\", 12), (\"b\" \"un\", 4), (\"hug\" \"s\", 5)\n",
        "```"
      ],
      "metadata": {
        "id": "k9shnCKyb5a4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing BPE\n",
        "\n",
        "Now let's take a look at an <font color='blue'>implementation</font> of the <font color='blue'>BPE algorithm</font>. This won't be an <font color='blue'>optimized version</font> you can actually use on a <font color='blue'>big corpus</font>; we just want to show you the code so you can understand the algorithm a little bit better.\n",
        "\n",
        "First we need a corpus, so let's create a simple one with a few sentences:"
      ],
      "metadata": {
        "id": "gvgxN2bCFVz4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PvOr15XBOvJ3"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"This is the Hugging Face Course.\",\n",
        "    \"This chapter is about tokenization.\",\n",
        "    \"This section shows several tokenizer algorithms.\",\n",
        "    \"Hopefully, you will be able to understand how they are trained and generate tokens.\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to <font color='blue'>pre-tokenize</font> that <font color='blue'>corpus</font> into <font color='blue'>words</font>. Since we are replicating a <font color='blue'>BPE tokenizer</font> (like GPT-2), we will use the <font color='blue'>`gpt2` tokenizer</font> for the pre-tokenization:"
      ],
      "metadata": {
        "id": "dsWWbZgVFeor"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tYpubex5OvJ4"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we <font color='blue'>compute</font> the <font color='blue'>frequencies</font> of <font color='blue'>each word</font> in the corpus as we do the pre-tokenization:\n"
      ],
      "metadata": {
        "id": "VmQ3YfPZFo0N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oUERLJclOvJ4",
        "outputId": "a55a5586-a7b0-43ab-ca63-8e3af1775187",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    'This': 3,\n",
            "    'Ġis': 2,\n",
            "    'Ġthe': 1,\n",
            "    'ĠHugging': 1,\n",
            "    'ĠFace': 1,\n",
            "    'ĠCourse': 1,\n",
            "    '.': 4,\n",
            "    'Ġchapter': 1,\n",
            "    'Ġabout': 1,\n",
            "    'Ġtokenization': 1,\n",
            "    'Ġsection': 1,\n",
            "    'Ġshows': 1,\n",
            "    'Ġseveral': 1,\n",
            "    'Ġtokenizer': 1,\n",
            "    'Ġalgorithms': 1,\n",
            "    'Hopefully': 1,\n",
            "    ',': 1,\n",
            "    'Ġyou': 1,\n",
            "    'Ġwill': 1,\n",
            "    'Ġbe': 1,\n",
            "    'Ġable': 1,\n",
            "    'Ġto': 1,\n",
            "    'Ġunderstand': 1,\n",
            "    'Ġhow': 1,\n",
            "    'Ġthey': 1,\n",
            "    'Ġare': 1,\n",
            "    'Ġtrained': 1,\n",
            "    'Ġand': 1,\n",
            "    'Ġgenerate': 1,\n",
            "    'Ġtokens': 1\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "word_freqs = defaultdict(int)\n",
        "\n",
        "for text in corpus:\n",
        "    words_with_offsets = tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
        "    new_words = [word for word, offset in words_with_offsets]\n",
        "    for word in new_words:\n",
        "        word_freqs[word] += 1\n",
        "\n",
        "# Display word frequencies\n",
        "for i, (word, freq) in enumerate(word_freqs.items()):\n",
        "    if i == len(word_freqs) - 1:\n",
        "        print(f\"    '{word}': {freq}\")\n",
        "    else:\n",
        "        print(f\"    '{word}': {freq},\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to <font color='blue'>compute</font> the <font color='blue'>base vocabulary</font>, formed by <font color='blue'>all the characters</font> used in the corpus:"
      ],
      "metadata": {
        "id": "gG57VdsEHe1b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7HnjwrtIOvJ5",
        "outputId": "72af8b02-037d-4ca9-c004-5e8661850ca1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[',', '.', 'C', 'F', 'H', 'T', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y', 'z', 'Ġ']\n"
          ]
        }
      ],
      "source": [
        "alphabet = []\n",
        "\n",
        "for word in word_freqs.keys():\n",
        "    for letter in word:\n",
        "        if letter not in alphabet:\n",
        "            alphabet.append(letter)\n",
        "alphabet.sort()\n",
        "\n",
        "print(alphabet)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also <font color='blue'>add</font> the <font color='blue'>special tokens</font> used by the model at the <font color='blue'>beginning</font> of that <font color='blue'>vocabulary</font>. In the case of GPT-2, the only special token is <font color='blue'>`\"<|endoftext|>\"`</font>:"
      ],
      "metadata": {
        "id": "TJpeym3TFxn3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZEG8ab-ROvJ6"
      },
      "outputs": [],
      "source": [
        "vocab = [\"<|endoftext|>\"] + alphabet.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now need to <font color='blue'>split</font> each <font color='blue'>word</font> into <font color='blue'>individual characters</font>, to be able to start training:"
      ],
      "metadata": {
        "id": "9Pt-G9uoF3hh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7q_A-x29OvJ6"
      },
      "outputs": [],
      "source": [
        "splits = {word: [c for c in word] for word in word_freqs.keys()}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we are ready for training, let's write a <font color='blue'>function</font> that <font color='blue'>computes</font> the <font color='blue'>frequency</font> of <font color='blue'>each pair</font>. We'll need to use this at each step of the training:"
      ],
      "metadata": {
        "id": "OPvuX-4uF4d6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1IR-FfG-OvJ7"
      },
      "outputs": [],
      "source": [
        "def compute_pair_freqs(splits):\n",
        "    pair_freqs = defaultdict(int)\n",
        "    for word, freq in word_freqs.items():\n",
        "        split = splits[word]\n",
        "        if len(split) == 1:\n",
        "            continue\n",
        "        for i in range(len(split) - 1):\n",
        "            pair = (split[i], split[i + 1])\n",
        "            pair_freqs[pair] += freq\n",
        "    return pair_freqs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a <font color='blue'>look</font> at a <font color='blue'>part</font> of this <font color='blue'>dictionary</font> after the initial splits:"
      ],
      "metadata": {
        "id": "MhDNh8MGF65L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iFVysw89OvJ8",
        "outputId": "c2a6c838-7141-4866-d3f9-d60808bd6526",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('T', 'h'): 3\n",
            "('h', 'i'): 3\n",
            "('i', 's'): 5\n",
            "('Ġ', 'i'): 2\n",
            "('Ġ', 't'): 7\n",
            "('t', 'h'): 3\n"
          ]
        }
      ],
      "source": [
        "pair_freqs = compute_pair_freqs(splits)\n",
        "\n",
        "for i, key in enumerate(pair_freqs.keys()):\n",
        "    print(f\"{key}: {pair_freqs[key]}\")\n",
        "    if i >= 5:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, finding the <font color='blue'>most frequent pair</font> only takes a <font color='blue'>quick loop</font>:"
      ],
      "metadata": {
        "id": "5H2HEHxhF8-u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "c3f68Ui1OvJ9",
        "outputId": "87ed450a-ac87-46c0-c5a0-cc672b733e4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Ġ', 't') 7\n"
          ]
        }
      ],
      "source": [
        "best_pair = \"\"\n",
        "max_freq = None\n",
        "\n",
        "for pair, freq in pair_freqs.items():\n",
        "    if max_freq is None or max_freq < freq:\n",
        "        best_pair = pair\n",
        "        max_freq = freq\n",
        "\n",
        "print(best_pair, max_freq)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the <font color='blue'>first merge</font> to learn is <font color='blue'>`('Ġ', 't') -> 'Ġt'`</font>, and we add <font color='blue'>`'Ġt'`</font> to the vocabulary:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K7qB5iAGF_Nx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dVIX9cAPOvJ9"
      },
      "outputs": [],
      "source": [
        "merges = {(\"Ġ\", \"t\"): \"Ġt\"}\n",
        "vocab.append(\"Ġt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To continue, we need to apply that <font color='blue'>merge</font> in our <font color='blue'>`splits` dictionary</font>. Let's write another function for this:"
      ],
      "metadata": {
        "id": "t-8qXwV0GCOV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "K0YqCakZOvJ-"
      },
      "outputs": [],
      "source": [
        "def merge_pair(a, b, splits):\n",
        "    for word in word_freqs:\n",
        "        split = splits[word]\n",
        "        if len(split) == 1:\n",
        "            continue\n",
        "\n",
        "        i = 0\n",
        "        while i < len(split) - 1:\n",
        "            if split[i] == a and split[i + 1] == b:\n",
        "                split = split[:i] + [a + b] + split[i + 2 :]\n",
        "            else:\n",
        "                i += 1\n",
        "        splits[word] = split\n",
        "    return splits"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "And we can have a <font color='blue'>look</font> at the <font color='blue'>result</font> of the <font color='blue'>first merge</font>:"
      ],
      "metadata": {
        "id": "q_xgKmVlGEkF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cY6yOU1MOvJ-",
        "outputId": "d8925dc9-7c46-489d-996b-3bb9212245e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ġt', 'r', 'a', 'i', 'n', 'e', 'd']\n"
          ]
        }
      ],
      "source": [
        "splits = merge_pair(\"Ġ\", \"t\", splits)\n",
        "print(splits[\"Ġtrained\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have everything we need to <font color='blue'>loop</font> until we have <font color='blue'>learned all</font> the <font color='blue'>merges</font> we want. Let's aim for a <font color='blue'>vocab size</font> of <font color='blue'>50</font>:"
      ],
      "metadata": {
        "id": "QkjCPvNCGGhB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Wh1zl428OvJ-"
      },
      "outputs": [],
      "source": [
        "vocab_size = 50\n",
        "\n",
        "while len(vocab) < vocab_size:\n",
        "    pair_freqs = compute_pair_freqs(splits)\n",
        "    best_pair = \"\"\n",
        "    max_freq = None\n",
        "    for pair, freq in pair_freqs.items():\n",
        "        if max_freq is None or max_freq < freq:\n",
        "            best_pair = pair\n",
        "            max_freq = freq\n",
        "    splits = merge_pair(*best_pair, splits)\n",
        "    merges[best_pair] = best_pair[0] + best_pair[1]\n",
        "    vocab.append(best_pair[0] + best_pair[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a result, we've learned <font color='blue'>19 merge rules</font> (the initial vocabulary had a size of <font color='blue'>31 -- 30 characters</font> in the <font color='blue'>alphabet</font>, plus the <font color='blue'>special token</font>):"
      ],
      "metadata": {
        "id": "fRbdD85tGJUR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "irAJgKSsOvJ_",
        "outputId": "973b342f-ed64-4e27-ae4e-ddf03ca03eef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:     '('Ġ', 't')': Ġt,\n",
            "2:     '('i', 's')': is,\n",
            "3:     '('e', 'r')': er,\n",
            "4:     '('Ġ', 'a')': Ġa,\n",
            "5:     '('Ġt', 'o')': Ġto,\n",
            "6:     '('e', 'n')': en,\n",
            "7:     '('T', 'h')': Th,\n",
            "8:     '('Th', 'is')': This,\n",
            "9:     '('o', 'u')': ou,\n",
            "10:     '('s', 'e')': se,\n",
            "11:     '('Ġto', 'k')': Ġtok,\n",
            "12:     '('Ġtok', 'en')': Ġtoken,\n",
            "13:     '('n', 'd')': nd,\n",
            "14:     '('Ġ', 'is')': Ġis,\n",
            "15:     '('Ġt', 'h')': Ġth,\n",
            "16:     '('Ġth', 'e')': Ġthe,\n",
            "17:     '('i', 'n')': in,\n",
            "18:     '('Ġa', 'b')': Ġab,\n",
            "19:    '('Ġtoken', 'i')': Ġtokeni\n"
          ]
        }
      ],
      "source": [
        "#print(merges)\n",
        "for i, (word, freq) in enumerate(merges.items()):\n",
        "    if i == len(merges) - 1:\n",
        "        print(f\"{i+1}:    '{word}': {freq}\")\n",
        "    else:\n",
        "        print(f\"{i+1}:     '{word}': {freq},\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the <font color='blue'>vocabulary</font> is composed of the <font color='blue'>special token</font>, the <font color='blue'>initial alphabet</font>, and all the <font color='blue'>results</font> of the <font color='blue'>merges</font>:"
      ],
      "metadata": {
        "id": "r5zfGvpvGLbr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rNpIPuu7OvJ_",
        "outputId": "6d7d4ebe-f67a-4625-d65b-c5f479d3acca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|endoftext|>\n",
            ",\n",
            ".\n",
            "C\n",
            "F\n",
            "H\n",
            "T\n",
            "a\n",
            "b\n",
            "c\n",
            "d\n",
            "e\n",
            "f\n",
            "g\n",
            "h\n",
            "i\n",
            "k\n",
            "l\n",
            "m\n",
            "n\n",
            "o\n",
            "p\n",
            "r\n",
            "s\n",
            "t\n",
            "u\n",
            "v\n",
            "w\n",
            "y\n",
            "z\n",
            "Ġ\n",
            "Ġt\n",
            "is\n",
            "er\n",
            "Ġa\n",
            "Ġto\n",
            "en\n",
            "Th\n",
            "This\n",
            "ou\n",
            "se\n",
            "Ġtok\n",
            "Ġtoken\n",
            "nd\n",
            "Ġis\n",
            "Ġth\n",
            "Ġthe\n",
            "in\n",
            "Ġab\n",
            "Ġtokeni\n"
          ]
        }
      ],
      "source": [
        "for ele in vocab:\n",
        "    print(ele)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<Tip>\n",
        "\n",
        "💡 Using <font color='blue'>`train_new_from_iterator()`</font> on the <font color='blue'>same corpus won't result</font> in the exact <font color='blue'>same vocabulary</font>. This is because when there is a <font color='blue'>choice</font> of the <font color='blue'>most frequent pair</font>, <font color='blue'>we selected</font> the <font color='blue'>first one encountered</font>, while the 🤗 <font color='blue'>Tokenizers library</font> selects the <font color='blue'>first one</font> based on its <font color='blue'>inner IDs</font>.\n",
        "\n",
        "</Tip>\n",
        "\n",
        "To tokenize a new text, we pre-tokenize it, split it, then apply all the merge rules learned:"
      ],
      "metadata": {
        "id": "wV3nFfPDGPSk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sSArosk_OvJ_"
      },
      "outputs": [],
      "source": [
        "def tokenize(text):\n",
        "    pre_tokenize_result = tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
        "    pre_tokenized_text = [word for word, offset in pre_tokenize_result]\n",
        "    splits = [[l for l in word] for word in pre_tokenized_text]\n",
        "    for pair, merge in merges.items():\n",
        "        for idx, split in enumerate(splits):\n",
        "            i = 0\n",
        "            while i < len(split) - 1:\n",
        "                if split[i] == pair[0] and split[i + 1] == pair[1]:\n",
        "                    split = split[:i] + [merge] + split[i + 2 :]\n",
        "                else:\n",
        "                    i += 1\n",
        "            splits[idx] = split\n",
        "\n",
        "    return sum(splits, [])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can try this on <font color='blue'>any text</font> composed of <font color='blue'>characters</font> in the <font color='blue'>alphabet</font>:"
      ],
      "metadata": {
        "id": "EuJD6poOGStI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "V3NQBlDzOvJ_",
        "outputId": "490ec58c-b073-411c-d861-b05b8e6adb1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'Ġis', 'Ġ', 'n', 'o', 't', 'Ġa', 'Ġtoken', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "tokenize(\"This is not a token.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<Tip warning={true}>\n",
        "\n",
        "⚠️ Our implementation will <font color='blue'>throw an error</font> if there is an <font color='blue'>unknown character</font> since we didn't do anything to handle them. <font color='blue'>GPT-2 doesn't</font> actually <font color='blue'>have</font> an <font color='blue'>unknown token</font> (it's <font color='blue'>impossible</font> to get an <font color='blue'>unknown character</font> when using <font color='blue'>byte-level BPE</font>), but this could happen here because we did not include <font color='blue'>all</font> the <font color='blue'>possible bytes</font> in the <font color='blue'>initial vocabulary</font>. This aspect of BPE is beyond the scope of this section, so we've left the details out.\n",
        "\n",
        "</Tip>\n",
        "\n",
        "That's it for the BPE algorithm! Next, we'll have a look at WordPiece."
      ],
      "metadata": {
        "id": "FnIa-zt7GVIj"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb565bcf42a9496a8ddcb5714381a5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_2e407ef96ca04ecf9a9e8429c44a874a"
          }
        },
        "2ae6d5bba7e142cdae5394d4fba9c780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a7048c7e1f54252866c2d08b844abfb",
            "placeholder": "​",
            "style": "IPY_MODEL_3788ee0c347f450ab9f91978b5fb32de",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "544784fb87a547bca297b28dbb277a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_52cba522632145a1beeea62d570a8b14",
            "placeholder": "​",
            "style": "IPY_MODEL_4961df58c64d45d5aad6d31fa1c2b57e",
            "value": ""
          }
        },
        "92c7c7473ae34ab684846ac93993dd8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_35b79a4c8e6941598e7ea2047fd04ccc",
            "style": "IPY_MODEL_56988d3d867447bf83f6c2bd3d16173f",
            "value": true
          }
        },
        "658930b52bd548a7bd2efe211839e170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_007767878d374b9e9a5e19674e575619",
            "style": "IPY_MODEL_8217b552968e407eab876521e0c86ec3",
            "tooltip": ""
          }
        },
        "79761247e44348acb3ee2423f9853504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98dd185e7aba44108b4da18c7a3e7c22",
            "placeholder": "​",
            "style": "IPY_MODEL_39736bf4168c493fa50e644c1091c604",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "2e407ef96ca04ecf9a9e8429c44a874a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "5a7048c7e1f54252866c2d08b844abfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3788ee0c347f450ab9f91978b5fb32de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52cba522632145a1beeea62d570a8b14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4961df58c64d45d5aad6d31fa1c2b57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35b79a4c8e6941598e7ea2047fd04ccc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56988d3d867447bf83f6c2bd3d16173f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "007767878d374b9e9a5e19674e575619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8217b552968e407eab876521e0c86ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "98dd185e7aba44108b4da18c7a3e7c22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39736bf4168c493fa50e644c1091c604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0033292f5d27416087cd09cffb0cd79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cca24d5e7f246c6b7c45e1e35dbdf69",
            "placeholder": "​",
            "style": "IPY_MODEL_02e4827c9e324653b8dea564dcb9c143",
            "value": "Connecting..."
          }
        },
        "5cca24d5e7f246c6b7c45e1e35dbdf69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02e4827c9e324653b8dea564dcb9c143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}