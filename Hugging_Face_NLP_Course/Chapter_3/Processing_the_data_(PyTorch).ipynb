{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy4Dz3KROKf-"
      },
      "source": [
        "# Processing the data (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McFnv6ShOKf_"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0IS7BxzkOKgA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, log into Hugging face"
      ],
      "metadata": {
        "id": "wCGxG1sz11XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "769a8fdf8ff84a63bd375cca3ba0b3bd",
            "6a0cc68b54a4448880b7c964fdea126b",
            "3c9e33fac1f84124958e255168779b33",
            "8b9004c7857d4e678a3934c33602feb9",
            "986126f60bb348d8935ae72bb1ecbaac",
            "a25fcde3b98e46f19d85dcfba0c50a49",
            "dfa0eab464ea4bb4a47a824ccb5d583b",
            "7eb6db34c06a4767bdb1d9016975f8ca",
            "56ab785a74a248ffbe2fbca8648b9850",
            "6d789fd6211240b7a118bcbf515d3999",
            "400c93e9c4bf4176b7bb9483fe330557",
            "968110e7a1334db6af14885b0ed0702d",
            "407d3d3428f648d78052cbff28372a1a",
            "778745e0965741328f533c330f9a5611",
            "7f1e54968cee4146a0e11589be34b81c",
            "7442bf1a377046ccbf8a8c577f8502a5",
            "3eceede48dae49d796be44f756adab95",
            "f538e7ab25f0414381168cc7b0c302cf",
            "cbe68ae0abc448479d8c5f4e89571018",
            "4d978a285db741d887adeca6c7444295",
            "3db6a2cfe0ba4d49815bedec1457bd3e",
            "f64690e613b248f6aa42a89b2ac035a4",
            "bcb4a0415ac64451a2f0e62f2ab9908a",
            "7094b8439fdc4beb9ef2a72e35a911ad",
            "d3342bf29b1243e5a942518c1abbcb7d",
            "5dc4f254e90842c5939faf4a8d23d76d",
            "c3c72286c18540b3ab3d1b2aa9ede36e",
            "14aa87ea586e47ce9400c59124268a9c",
            "0de6580e860f4890a2f981cf399d8b66",
            "9a3c22b8b85446aa9a00553cb43d18ca",
            "f13ff5c3412345418845afd88b8db1e5",
            "451121f8ad8e45d5bacc842ed5ba499e"
          ]
        },
        "id": "0LErvW0L12zt",
        "outputId": "1cd15e88-de65-4c03-cda8-54e7ef9403ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "769a8fdf8ff84a63bd375cca3ba0b3bd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continuing with the example from the [previous chapter](https://huggingface.co/course/chapter2), here is how we would train a <font color='blue'>sequence classifier</font> on <font color='blue'>one batch</font> in PyTorch:"
      ],
      "metadata": {
        "id": "WJXUpSLXOLrJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F69j1DkWOKgA",
        "outputId": "028794be-0e59-4470-faa9-0cf62ccc978d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Same as Chapter 2\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "sequences = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"This course is amazing!\",\n",
        "]\n",
        "batch = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# New code\n",
        "batch[\"labels\"] = torch.tensor([1, 1])\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters())\n",
        "loss = model(**batch).loss\n",
        "loss.backward()\n",
        "optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course, just training the model on two sentences is not going to yield very good results. To get <font color='blue'>better results</font>, you will need to prepare a <font color='blue'>bigger dataset</font>.\n",
        "\n",
        "In this section we will use as an example the <font color='blue'>Microsoft Research Paraphrase Corpus</font> dataset, introduced in a [paper](https://www.aclweb.org/anthology/I05-5002.pdf) by William B. Dolan and Chris Brockett. The dataset consists of <font color='blue'>5,801 pairs</font> of <font color='blue'>sentences</font>, with a <font color='blue'>label indicating</font> if they are <font color='blue'>paraphrase</font> or not (i.e., if <font color='blue'>both</font> sentences <font color='blue'>mean</font> the <font color='blue'>same thing</font>). We've selected it for this chapter because it's a small dataset, so it's easy to experiment with training on it.\n",
        "\n",
        "**Loading a dataset from the Hub**\n",
        "\n",
        "The Hub doesn't just contain models; it also has <font color='blue'>multiple datasets</font> in lots of <font color='blue'>different languages</font>. You can browse the datasets [here](https://huggingface.co/datasets), and we recommend you <font color='blue'>try</font> to <font color='blue'>load and process a new dataset</font> once you have gone through this section (see the general documentation [here](https://huggingface.co/docs/datasets/loading)). But for now, let's focus on the <font color='blue'>MRPC dataset</font>. This is one of the 10 datasets composing the [GLUE benchmark](https://gluebenchmark.com/), which is an <font color='blue'>academic benchmark</font> that is used to measure the <font color='blue'>performance</font> of <font color='blue'>ML models</font> across 10 different text classification tasks.\n",
        "\n",
        "The ðŸ¤— Datasets library provides a simple command to <font color='blue'>download</font> and <font color='blue'>cache</font> a <font color='blue'>dataset</font> on the <font color='blue'>Hub</font>. We can download the MRPC dataset like this:"
      ],
      "metadata": {
        "id": "euWvwZR9OUfo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rv-kNe8VOKgB",
        "outputId": "db1292c2-9049-4e0e-96c2-6eb4c1758236",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 3668\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 408\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 1725\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "raw_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, we get a <font color='blue'>`DatasetDict` object</font> which contains the <font color='blue'>training</font> set, the <font color='blue'>validation</font> set, and the <font color='blue'>test</font> set. Each of those contains <font color='blue'>several columns</font> (`sentence1`, `sentence2`, `label`, and `idx`) and a <font color='blue'>variable number</font> of <font color='blue'>rows</font>, which are the number of elements in each set (so, there are 3,668 pairs of sentences in the training set, 408 in the validation set, and 1,725 in the test set).\n",
        "\n",
        "This command <font color='blue'>downloads</font> and <font color='blue'>caches the dataset</font>, by default in `~/.cache/huggingface/datasets`. Recall from Chapter 2 that you can customize your cache folder by setting the `HF_HOME` environment variable.\n",
        "\n",
        "We can <font color='blue'>access each pair</font> of <font color='blue'>sentences</font> in our `raw_datasets` object by <font color='blue'>indexing</font>, like with a dictionary:"
      ],
      "metadata": {
        "id": "7M8hS6tfQJ6C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nbixDSU9OKgC",
        "outputId": "12153320-7dbf-4816-f923-15c4b9778a75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
              " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
              " 'label': 1,\n",
              " 'idx': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "raw_train_dataset = raw_datasets[\"train\"]\n",
        "raw_train_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the <font color='blue'>labels</font> are <font color='blue'>already integers</font>, so we won't have to do any preprocessing there. To know <font color='blue'>which integer</font> corresponds to <font color='blue'>which label</font>, we can <font color='blue'>inspect</font> the <font color='blue'>features</font> of our <font color='blue'>`raw_train_dataset`</font>. This will tell us the type of each column:"
      ],
      "metadata": {
        "id": "8IKX0hBzRGAZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5Buy24wKOKgC",
        "outputId": "b314aced-292e-41a0-e983-901aac038983",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence1': Value(dtype='string', id=None),\n",
              " 'sentence2': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n",
              " 'idx': Value(dtype='int32', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "raw_train_dataset.features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Behind the scenes, <font color='blue'>label</font> is of <font color='blue'>type `ClassLabel`</font>, and the <font color='blue'>mapping</font> of <font color='blue'>integers to label name</font> is stored in the <font color='blue'>`names` folder</font>. In these:\n",
        "\n",
        "- <font color='blue'>0</font> corresponds to <font color='blue'>not_equivalent</font>,\n",
        "- and <font color='blue'>1</font> corresponds to <font color='blue'>equivalent</font>.\n",
        "\n",
        "**Try it out!** Look at element 15 of the training set and element 87 of the validation set. What are their labels?"
      ],
      "metadata": {
        "id": "mWa13gY7ROsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise\n",
        "raw_train_dataset = raw_datasets[\"train\"]\n",
        "raw_train_dataset[14]     # Element 15 of the training set"
      ],
      "metadata": {
        "id": "6PT-EUOYRaIo",
        "outputId": "47154a84-3a12-4010-cf25-8d7d518aa997",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence1': 'Gyorgy Heizler , head of the local disaster unit , said the coach was carrying 38 passengers .',\n",
              " 'sentence2': 'The head of the local disaster unit , Gyorgy Heizler , said the coach driver had failed to heed red stop lights .',\n",
              " 'label': 0,\n",
              " 'idx': 15}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_dataset = raw_datasets[\"validation\"]\n",
        "raw_train_dataset[86]     # Element 87 of the validation set"
      ],
      "metadata": {
        "id": "8_CxuVB2Stbd",
        "outputId": "628fa5b7-32dc-4eba-c950-adff24bf006f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence1': 'He was arrested Friday night at an Alpharetta seafood restaurant while dining with his wife , singer Whitney Houston .',\n",
              " 'sentence2': 'He was arrested again Friday night at an Alpharetta restaurant where he was having dinner with his wife .',\n",
              " 'label': 1,\n",
              " 'idx': 796}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing a dataset**"
      ],
      "metadata": {
        "id": "3q9VqlcSRaOn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To <font color='blue'>preprocess</font> the <font color='blue'>dataset</font>, we need to <font color='blue'>convert</font> the <font color='blue'>text to numbers</font> the model can make sense of. As you saw in the [previous chapter](https://huggingface.co/course/chapter2), this is done with a <font color='blue'>tokenizer</font>. We can <font color='blue'>feed</font> the <font color='blue'>tokenizer one sentence</font> or a <font color='blue'>list of sentences</font>, so we can <font color='blue'>directly tokenize</font> all the first sentences and all the second sentences of each pair like this:"
      ],
      "metadata": {
        "id": "T0_wWvR0ywez"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ov_MvyomOKgD"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "tokenized_sentences_1 = tokenizer(raw_datasets[\"train\"][\"sentence1\"])\n",
        "tokenized_sentences_2 = tokenizer(raw_datasets[\"train\"][\"sentence2\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, we <font color='blue'>can't</font> just <font color='blue'>pass two sequences</font> to the <font color='blue'>model</font> and <font color='blue'>get a prediction</font> of whether the <font color='blue'>two sentences</font> are <font color='blue'>paraphrases</font> or not. We need to handle the <font color='blue'>two sequences</font> as a <font color='blue'>pair</font>, and <font color='blue'>apply</font> the <font color='blue'>appropriate preprocessing</font>. Fortunately, the <font color='blue'>tokenizer</font> can also take a <font color='blue'>pair of sequences</font> and <font color='blue'>prepare it</font> the way our BERT model expects:\n",
        "\n"
      ],
      "metadata": {
        "id": "VDFJoS1Cy-Mu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fHGWniFWOKgD",
        "outputId": "141325a1-14ce-4de6-c1d4-54e9c1de3eb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids: [101, 2023, 2003, 1996, 2034, 6251, 1012, 102, 2023, 2003, 1996, 2117, 2028, 1012, 102]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
            "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(\"This is the first sentence.\", \"This is the second one.\")\n",
        "for key, value in inputs.items():\n",
        "    print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We discussed the <font color='blue'>input_ids</font> and <font color='blue'>attention_mask</font> keys in [Chapter 2](https://huggingface.co/course/chapter2), but we put off talking about <font color='blue'>token_type_ids</font>. In this example, this is what <font color='blue'>tells the model</font> which <font color='blue'>part</font> of the <font color='blue'>input</font> is the <font color='blue'>first sentence</font> and which is the <font color='blue'>second sentence</font>."
      ],
      "metadata": {
        "id": "-2dqLFTSzGjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Try it out!** Take element 15 of the training set and tokenize the two sentences separately and as a pair. What's the difference between the two results?"
      ],
      "metadata": {
        "id": "Y5rmieBpza2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is what happens when you tokenize the two sentences separately:"
      ],
      "metadata": {
        "id": "VX9a8Mgr6Ur1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "ele15 = raw_datasets[\"train\"][14]\n",
        "tokenized_sentences_1 = tokenizer(ele15[\"sentence1\"])\n",
        "tokenized_sentences_2 = tokenizer(ele15[\"sentence2\"])\n",
        "for key in tokenized_sentences_1:\n",
        "  print(key, tokenized_sentences_1[key])\n",
        "print()\n",
        "for key in tokenized_sentences_2:\n",
        "  print(key, tokenized_sentences_2[key])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6Dk393pzdva",
        "outputId": "6dbac0e4-e4c8-44a3-da6c-15256fa55d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids [101, 1043, 7677, 22637, 2002, 10993, 3917, 1010, 2132, 1997, 1996, 2334, 7071, 3131, 1010, 2056, 1996, 2873, 2001, 4755, 4229, 5467, 1012, 102]\n",
            "token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "\n",
            "input_ids [101, 1996, 2132, 1997, 1996, 2334, 7071, 3131, 1010, 1043, 7677, 22637, 2002, 10993, 3917, 1010, 2056, 1996, 2873, 4062, 2018, 3478, 2000, 18235, 2094, 2417, 2644, 4597, 1012, 102]\n",
            "token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the input_ids have a starting and closing token and `token_type_ids` for a single sentence. When you tokenize the two sentences as a pair it combines both sentences in `inputs_ids` and `token_type_ids`:"
      ],
      "metadata": {
        "id": "7o9fpJax6aYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "ele15 = raw_datasets[\"train\"][14]\n",
        "tokenized_sentences_both = tokenizer(ele15[\"sentence1\"], ele15[\"sentence2\"])\n",
        "for key in tokenized_sentences_both:\n",
        "  print(key, tokenized_sentences_both[key]) # The token type id tells you which sentence the token came from"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDL_kzGs0TsR",
        "outputId": "e1eb9698-2a37-4999-93d1-eaa5148929a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids [101, 1043, 7677, 22637, 2002, 10993, 3917, 1010, 2132, 1997, 1996, 2334, 7071, 3131, 1010, 2056, 1996, 2873, 2001, 4755, 4229, 5467, 1012, 102, 1996, 2132, 1997, 1996, 2334, 7071, 3131, 1010, 1043, 7677, 22637, 2002, 10993, 3917, 1010, 2056, 1996, 2873, 4062, 2018, 3478, 2000, 18235, 2094, 2417, 2644, 4597, 1012, 102]\n",
            "token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "attention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we <font color='blue'>decode</font> the <font color='blue'>IDs</font> inside `input_ids` <font color='blue'>back to words</font> we will get:"
      ],
      "metadata": {
        "id": "RGWWxgJP2WAe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jikihZOEOKgE",
        "outputId": "fd05bc14-9e42-44da-f1e3-08bba470b2e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'this',\n",
              " 'is',\n",
              " 'the',\n",
              " 'first',\n",
              " 'sentence',\n",
              " '.',\n",
              " '[SEP]',\n",
              " 'this',\n",
              " 'is',\n",
              " 'the',\n",
              " 'second',\n",
              " 'one',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we see the <font color='blue'>model expects</font> the <font color='blue'>inputs</font> to be <font color='blue'>of the form</font> `[CLS]` sentence1 `[SEP]` sentence2 `[SEP]` when there are <font color='blue'>two sentences</font>. Aligning this with the `token_type_ids` gives us:"
      ],
      "metadata": {
        "id": "NxxK2YrH2dMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"]))\n",
        "print(inputs[\"token_type_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02eAYEvs2ldD",
        "outputId": "6655af97-d119-41da-f25f-06ec46959165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'this', 'is', 'the', 'first', 'sentence', '.', '[SEP]', 'this', 'is', 'the', 'second', 'one', '.', '[SEP]']\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the parts of the input corresponding to <font color='blue'>`[CLS]` sentence1 `[SEP]`</font> all have a <font color='blue'>token type ID</font> of 0</font>, while the <font color='blue'>other parts</font>, corresponding to sentence2 `[SEP]`, all have a <font color='blue'>token type ID</font> of <font color='blue'>1</font>.\n",
        "\n",
        "Note that if you select a <font color='blue'>different checkpoint</font>, you won't necessarily have the <font color='blue'>`token_type_ids`</font> in <font color='blue'>your tokenized inputs</font> (for instance, they're not returned if you use a DistilBERT model). They are <font color='blue'>only returned</font> when the <font color='blue'>model</font> will <font color='blue'>know what to do with them</font>, because it has <font color='blue'>seen them</font> during its <font color='blue'>pretraining</font>.\n",
        "\n",
        "Here, <font color='blue'>BERT</font> is <font color='blue'>pretrained</font> with <font color='blue'>token type IDs</font>, and on top of the masked language modeling objective we talked about in [Chapter 1](https://huggingface.co/course/chapter1), it has an <font color='blue'>additional objective</font> called <font color='blue'>next sentence prediction</font>. The goal with this task is to <font color='blue'>model the relationship</font> between <font color='blue'>pairs of sentences</font>.\n",
        "\n",
        "With next sentence prediction, the <font color='blue'>model</font> is provided <font color='blue'>pairs of sentences</font> (with randomly masked tokens) and <font color='blue'>asked to predict</font> whether the <font color='blue'>second</font> sentence <font color='blue'>follows the first</font>. To make the task non-trivial, <font color='blue'>half of the time</font> the <font color='blue'>sentences follow each other</font> in the original document they were extracted from, and the other half of the time the two sentences come from two different documents.\n",
        "\n",
        "In general, you <font color='blue'>don't need to worry</font> about whether or not there are `token_type_ids` in your tokenized inputs: <font color='blue'>**as long as you use the same checkpoint for the tokenizer and the model**</font>, everything will be fine as the tokenizer knows what to provide to its model.\n",
        "\n",
        "Now that we have seen how our tokenizer can deal with <font color='blue'>one pair of sentences</font>, we can use it to <font color='blue'>tokenize our whole dataset</font>: like in the [previous chapter](https://huggingface.co/course/chapter2), we can <font color='blue'>feed</font> the tokenizer a <font color='blue'>list of pairs of sentences</font> by giving it the list of first sentences, then the list of second sentences. This is also compatible with the padding and truncation options we saw in [Chapter 2](https://huggingface.co/course/chapter2). So, one way to preprocess the training dataset is:"
      ],
      "metadata": {
        "id": "WPZVW_aA205x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-euot2WwOKgE"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = tokenizer(\n",
        "    raw_datasets[\"train\"][\"sentence1\"],\n",
        "    raw_datasets[\"train\"][\"sentence2\"],\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This works well, but it has the <font color='blue'>disadvantage</font> of <font color='blue'>returning a dictionary</font> (with our `keys`, `input_ids`, `attention_mask`, and `token_type_ids`, and values that are `lists of lists`). It will also only work if you have <font color='blue'>enough RAM</font> to <font color='blue'>store</font> your <font color='blue'>whole dataset</font> during the tokenization (whereas the datasets from the ðŸ¤— Datasets library are [Apache Arrow](https://arrow.apache.org/) files stored on the disk, so you only keep the samples you ask for loaded in memory).\n",
        "\n",
        "To <font color='blue'>keep</font> the <font color='blue'>data as a dataset</font>, we will use the [Dataset.map()](https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset.map) method. This also allows us some <font color='blue'>extra flexibility</font>, if we need <font color='blue'>more preprocessing</font> done than <font color='blue'>just tokenization</font>. The `map()` method works by <font color='blue'>applying a function</font> on <font color='blue'>each element</font> of the <font color='blue'>dataset</font>, so let's define a function that tokenizes our inputs:"
      ],
      "metadata": {
        "id": "cT_MUmef3f-T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "W9B3wHocOKgF"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function takes a <font color='blue'>dictionary</font> (like the items of our dataset) and <font color='blue'>returns</font> a <font color='blue'>new dictionary</font> with the <font color='blue'>keys</font> `input_ids`, `attention_mask`, and `token_type_ids`. Note that it <font color='blue'>also works</font> if the example dictionary contains <font color='blue'>several samples</font> (each key as a list of sentences) since the <font color='blue'>tokenizer</font> works on <font color='blue'>lists of pairs</font> of <font color='blue'>sentences</font>, as seen before. This will allow us to use the option <font color='blue'>`batched=True`</font> in our call to `map()`, which will greatly <font color='blue'>speed up</font> the <font color='blue'>tokenization</font>. The <font color='blue'>**tokenizer**</font> is <font color='blue'>**backed by a tokenizer written in Rust**</font> from the [ðŸ¤— Tokenizers](https://github.com/huggingface/tokenizers) library. This tokenizer can be very fast, but only if we give it lots of inputs at once.\n",
        "\n",
        "Note that we've <font color='blue'>left</font> the <font color='blue'>padding argument out</font> in our tokenization function for now. This is because <font color='blue'>padding all the samples</font> to the <font color='blue'>maximum length</font> is <font color='blue'>not efficient</font>: it's better to <font color='blue'>pad the samples</font> when we're <font color='blue'>building a batch</font>, as then we only need to pad to the maximum length in that batch, and not the maximum length in the entire dataset. This can save a lot of time and processing power when the inputs have very variable lengths!\n",
        "\n",
        "Here is how we <font color='blue'>apply</font> the <font color='blue'>tokenization function</font> on <font color='blue'>all our datasets</font> at once. We're using `batched=True` in our call to map so the function is <font color='blue'>applied to multiple elements</font> of our <font color='blue'>dataset at once</font>, and not on each element separately. This allows for faster preprocessing.\n",
        "\n",
        "The way the ðŸ¤— Datasets library applies this processing is by adding new fields to the datasets, one for each key in the dictionary returned by the preprocessing function:"
      ],
      "metadata": {
        "id": "mjhowMgQ383A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wCi21jsWOKgF",
        "outputId": "4f917f5a-fb7d-4ba5-acef-8b341796fc0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 3668\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 408\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 1725\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can even use <font color='blue'>multiprocessing</font> when <font color='blue'>applying your preprocessing function</font> with `map()` by passing along a <font color='blue'>`num_proc`</font> argument. We didn't do this here because the ðŸ¤— Tokenizers library already <font color='blue'>uses multiple threads</font> to tokenize our samples faster, but if you are not using a fast tokenizer backed by this library, this could speed up your preprocessing.\n",
        "\n",
        "Our `tokenize_function` returns a dictionary with the keys `input_ids`, `attention_mask`, and `token_type_ids`, so those <font color='blue'>three fields</font> are <font color='blue'>added to all splits</font> of our <font color='blue'>dataset</font>. Note that we could also have <font color='blue'>changed existing fields</font> if our <font color='blue'>preprocessing function</font> returned a <font color='blue'>new value</font> for an <font color='blue'>existing key</font> in the dataset to which we applied `map()`.\n",
        "\n",
        "The last thing we will need to do is <font color='blue'>pad all the examples</font> to the <font color='blue'>length of the longest element</font> when we batch elements together â€” a technique we refer to as <font color='blue'>dynamic padding</font>."
      ],
      "metadata": {
        "id": "fBsU7LRa5fB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dynamic padding**\n",
        "\n",
        "The function that is responsible for putting together samples inside a batch is called a <font color='blue'>collate function</font>. It's an <font color='blue'>argument</font> you can <font color='blue'>pass</font> when you build a <font color='blue'>DataLoader</font>, the <font color='blue'>default</font> being a <font color='blue'>function</font> that will just <font color='blue'>convert your samples</font> to <font color='blue'>PyTorch tensors</font> and <font color='blue'>concatenate</font> them (recursively if your elements are lists, tuples, or dictionaries). This <font color='blue'>won't</font> be possible in our case since the <font color='blue'>inputs</font> we have <font color='blue'>won't all be</font> of the <font color='blue'>same size</font>. We have deliberately postponed the padding, to only apply it as necessary on each batch and avoid having over-long inputs with a lot of padding. This will speed up training by quite a bit, but note that if you're training on a TPU it can cause problems â€” TPUs prefer fixed shapes, even when that requires extra padding.\n",
        "\n",
        "To do this in practice, we have to define a <font color='blue'>collate function</font> that will apply the <font color='blue'>correct amount of padding</font> to the <font color='blue'>items of the dataset</font> we want to <font color='blue'>batch together</font>. Fortunately, the ðŸ¤— Transformers library provides us with such a function via <font color='blue'>`DataCollatorWithPadding`</font>. It <font color='blue'>takes a tokenizer</font> when you <font color='blue'>instantiate it</font> (to know which padding token to use, and whether the model expects padding to be on the left or on the right of the inputs) and will do everything you need:"
      ],
      "metadata": {
        "id": "Wkw8-YUy5wtJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DN7f_UJ4OKgG"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To test this new toy, let's <font color='blue'>grab</font> a <font color='blue'>few samples</font> from our <font color='blue'>training set</font> that we would like to <font color='blue'>batch together</font>. Here, we <font color='blue'>remove</font> the <font color='blue'>columns `idx`, `sentence1`, and `sentence2`</font> as they <font color='blue'>won't be needed</font> and <font color='blue'>contain strings</font> (and we can't create tensors with strings) and have a look at the lengths of each entry in the batch:"
      ],
      "metadata": {
        "id": "utaXE8fG6QAX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "FjL_hAgZOKgG",
        "outputId": "5b3cc103-fdfc-4415-be12-1d371d2c4e70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[50, 59, 47, 67, 59, 50, 62, 32]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "samples = tokenized_datasets[\"train\"][:8]\n",
        "samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}\n",
        "[len(x) for x in samples[\"input_ids\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No surprise, we get <font color='blue'>samples</font> of <font color='blue'>varying length</font>, from <font color='blue'>32 to 67</font>. <font color='blue'>Dynamic padding</font> means the <font color='blue'>samples in this batch</font> should all be <font color='blue'>padded</font> to a <font color='blue'>length of 67</font>, the <font color='blue'>maximum length</font> inside the <font color='blue'>batch</font>. Without dynamic padding, all of the samples would have to be padded to the maximum length in the whole dataset, or the maximum length the model can accept. Let's double-check that our data_collator is dynamically padding the batch properly:"
      ],
      "metadata": {
        "id": "tPy_26gQ6fYk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "upQ8mqAZOKgG",
        "outputId": "29d48fc3-a485-441e-e848-309092abf538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': torch.Size([8, 67]),\n",
              " 'token_type_ids': torch.Size([8, 67]),\n",
              " 'attention_mask': torch.Size([8, 67]),\n",
              " 'labels': torch.Size([8])}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "batch = data_collator(samples)\n",
        "{k: v.shape for k, v in batch.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking good! Now that we've gone from <font color='blue'>raw text</font> to <font color='blue'>batches</font> our model can deal with, we're <font color='blue'>ready to fine-tune</font> it!"
      ],
      "metadata": {
        "id": "37cGAbt96knB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try it out!** Replicate the preprocessing on the GLUE SST-2 dataset. It's a little bit different since it's composed of single sentences instead of pairs, but the rest of what we did should look the same. For a harder challenge, try to write a preprocessing function that works on any of the GLUE tasks."
      ],
      "metadata": {
        "id": "iA2Ff0se6pq5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the GLUE SST-2 dataset using the Hugging Face Transformers library:** We will go through the process of preprocessing the [GLUE SST-2 dataset](https://huggingface.co/datasets/gimmaru/glue-sst2) using the Hugging Face Transformers library. The SST-2 dataset is a single-sentence text classification task, making it slightly different from other GLUE tasks that involve pairs of sentences. We'll cover loading the dataset, tokenization, and dynamic padding."
      ],
      "metadata": {
        "id": "DGSY8DVh7EWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Loading the Dataset:**\n",
        "\n",
        "We'll start by loading the SST-2 dataset from the ðŸ¤— Datasets library. This dataset consists of single sentences along with their corresponding labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "vf66a7WN7RH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "raw_datasets = load_dataset(\"glue\", \"sst2\")"
      ],
      "metadata": {
        "id": "O-Jp6p9H6mzu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Tokenization and Preprocessing:**\n",
        "\n",
        "Now that we have the raw dataset, let's preprocess the data by tokenizing the sentences using a pretrained tokenizer. We'll define a tokenization function and then apply it to the entire dataset."
      ],
      "metadata": {
        "id": "pmJvIOKr7Zgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence\"], truncation=True)\n",
        "\n",
        "# Tokenize the entire dataset\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69,
          "referenced_widgets": [
            "7fdb986d5f7d4fd5a019ae513a45adda",
            "b45d364e2369450e8e2d15789d09ac0a",
            "48a20871bd9b42f6a397c4a51ec21dbc",
            "8b6c0495a6ae4001b776faca8c18ea16",
            "dfe4a3c97f0d44da92c720aef2518365",
            "18517bb9881644bfb42acad9a90f208a",
            "ad9d72dcd2fd41db877d38e8cf081c20",
            "dea6a953bf514babbf67b75964ba14a4",
            "ca7737cf854a483a9ffe23652a25fcfe",
            "e8a1cea735e841329ef9bd2be0b887f4",
            "333571382f2e4a7c85575331f8f8c566"
          ]
        },
        "id": "GPtOdeYT7gZ-",
        "outputId": "7f61cc45-415a-4e80-de48-ffe4cca70780"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fdb986d5f7d4fd5a019ae513a45adda"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Dynamic Padding:**\n",
        "\n",
        "Dynamic padding allows us to pad the batch to the length of the longest sequence within that batch, instead of padding to the maximum sequence length in the entire dataset. This improves efficiency by reducing unnecessary padding."
      ],
      "metadata": {
        "id": "QaJXcxTt7mzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Example: Select a few samples from the training set\n",
        "samples = tokenized_datasets[\"train\"][:8]\n",
        "samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence\"]}\n",
        "\n",
        "# Apply dynamic padding using data_collator\n",
        "batch = data_collator(samples)\n",
        "\n",
        "{k: v.shape for k, v in batch.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dh3RrYE7quo",
        "outputId": "529fc16f-1558-45a3-cd8e-368d76a2380b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': torch.Size([8, 29]),\n",
              " 'token_type_ids': torch.Size([8, 29]),\n",
              " 'attention_mask': torch.Size([8, 29]),\n",
              " 'labels': torch.Size([8])}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The batch dictionary now contains keys for `input_ids`, `attention_mask`, `token_type_ids`, and `labels`, each corresponding to a PyTorch tensor. The `attention_mask` indicates which tokens are padding tokens, and `token_type_ids` distinguish between `sentences` in paired tasks."
      ],
      "metadata": {
        "id": "ritn4k1f8eRA"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "769a8fdf8ff84a63bd375cca3ba0b3bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3db6a2cfe0ba4d49815bedec1457bd3e",
              "IPY_MODEL_f64690e613b248f6aa42a89b2ac035a4",
              "IPY_MODEL_bcb4a0415ac64451a2f0e62f2ab9908a",
              "IPY_MODEL_7094b8439fdc4beb9ef2a72e35a911ad"
            ],
            "layout": "IPY_MODEL_dfa0eab464ea4bb4a47a824ccb5d583b"
          }
        },
        "6a0cc68b54a4448880b7c964fdea126b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7eb6db34c06a4767bdb1d9016975f8ca",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_56ab785a74a248ffbe2fbca8648b9850",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "3c9e33fac1f84124958e255168779b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6d789fd6211240b7a118bcbf515d3999",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_400c93e9c4bf4176b7bb9483fe330557",
            "value": ""
          }
        },
        "8b9004c7857d4e678a3934c33602feb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_968110e7a1334db6af14885b0ed0702d",
            "style": "IPY_MODEL_407d3d3428f648d78052cbff28372a1a",
            "value": true
          }
        },
        "986126f60bb348d8935ae72bb1ecbaac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_778745e0965741328f533c330f9a5611",
            "style": "IPY_MODEL_7f1e54968cee4146a0e11589be34b81c",
            "tooltip": ""
          }
        },
        "a25fcde3b98e46f19d85dcfba0c50a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7442bf1a377046ccbf8a8c577f8502a5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3eceede48dae49d796be44f756adab95",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "dfa0eab464ea4bb4a47a824ccb5d583b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "7eb6db34c06a4767bdb1d9016975f8ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ab785a74a248ffbe2fbca8648b9850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d789fd6211240b7a118bcbf515d3999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "400c93e9c4bf4176b7bb9483fe330557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "968110e7a1334db6af14885b0ed0702d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "407d3d3428f648d78052cbff28372a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "778745e0965741328f533c330f9a5611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f1e54968cee4146a0e11589be34b81c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "7442bf1a377046ccbf8a8c577f8502a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eceede48dae49d796be44f756adab95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f538e7ab25f0414381168cc7b0c302cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbe68ae0abc448479d8c5f4e89571018",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4d978a285db741d887adeca6c7444295",
            "value": "Connecting..."
          }
        },
        "cbe68ae0abc448479d8c5f4e89571018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d978a285db741d887adeca6c7444295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3db6a2cfe0ba4d49815bedec1457bd3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3342bf29b1243e5a942518c1abbcb7d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5dc4f254e90842c5939faf4a8d23d76d",
            "value": "Token is valid (permission: write)."
          }
        },
        "f64690e613b248f6aa42a89b2ac035a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3c72286c18540b3ab3d1b2aa9ede36e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_14aa87ea586e47ce9400c59124268a9c",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "bcb4a0415ac64451a2f0e62f2ab9908a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0de6580e860f4890a2f981cf399d8b66",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9a3c22b8b85446aa9a00553cb43d18ca",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "7094b8439fdc4beb9ef2a72e35a911ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f13ff5c3412345418845afd88b8db1e5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_451121f8ad8e45d5bacc842ed5ba499e",
            "value": "Login successful"
          }
        },
        "d3342bf29b1243e5a942518c1abbcb7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dc4f254e90842c5939faf4a8d23d76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3c72286c18540b3ab3d1b2aa9ede36e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14aa87ea586e47ce9400c59124268a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0de6580e860f4890a2f981cf399d8b66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a3c22b8b85446aa9a00553cb43d18ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f13ff5c3412345418845afd88b8db1e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "451121f8ad8e45d5bacc842ed5ba499e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fdb986d5f7d4fd5a019ae513a45adda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b45d364e2369450e8e2d15789d09ac0a",
              "IPY_MODEL_48a20871bd9b42f6a397c4a51ec21dbc",
              "IPY_MODEL_8b6c0495a6ae4001b776faca8c18ea16"
            ],
            "layout": "IPY_MODEL_dfe4a3c97f0d44da92c720aef2518365"
          }
        },
        "b45d364e2369450e8e2d15789d09ac0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18517bb9881644bfb42acad9a90f208a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ad9d72dcd2fd41db877d38e8cf081c20",
            "value": "Map:â€‡100%"
          }
        },
        "48a20871bd9b42f6a397c4a51ec21dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dea6a953bf514babbf67b75964ba14a4",
            "max": 1821,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca7737cf854a483a9ffe23652a25fcfe",
            "value": 1821
          }
        },
        "8b6c0495a6ae4001b776faca8c18ea16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8a1cea735e841329ef9bd2be0b887f4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_333571382f2e4a7c85575331f8f8c566",
            "value": "â€‡1821/1821â€‡[00:00&lt;00:00,â€‡5823.25â€‡examples/s]"
          }
        },
        "dfe4a3c97f0d44da92c720aef2518365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18517bb9881644bfb42acad9a90f208a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad9d72dcd2fd41db877d38e8cf081c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dea6a953bf514babbf67b75964ba14a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7737cf854a483a9ffe23652a25fcfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8a1cea735e841329ef9bd2be0b887f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "333571382f2e4a7c85575331f8f8c566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}