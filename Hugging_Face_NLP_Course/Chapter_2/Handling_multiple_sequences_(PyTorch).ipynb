{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvLlczvN7ZIk"
      },
      "source": [
        "# Handling multiple sequences (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErgxxIT37ZIl"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_1DrvPw7ZIl"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, log into Hugging face"
      ],
      "metadata": {
        "id": "fO2Gj4FA6dDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "ad7ff7a7e36648c6baf26e50704632d9",
            "6990019b41794d03aebacac331aa8787",
            "dae49bad1bca4088a94294c9a618b5c3",
            "6909081054ad4e86817483d913dfa893",
            "f4d93b25c07c4d00a9e9f8ca82b14a79",
            "e31ceb7bff05434f847e6d75120fc490",
            "545de1b009ff4712a290efcb13806b66",
            "3b45018ef4ad408b8d3d8ab564a6dd8f",
            "7ac9da6bc1764e45b30a31e865da6c7e",
            "1a276d0918c3402ab3aa15b706dc1134",
            "bedca7f2962a41dda9a3c596011834c4",
            "2c481a9a36194d29925108221220cc5a",
            "b97af72cbbf24b8cbfec9dbc67184470",
            "e01d14f74dc04d08af9f9a919f9fbca6",
            "da235c328ddf4541a978aae5a6385a48",
            "ef85ec37754e4d9093927294da7ac0dc",
            "84bdd411665a448293472988b7e54683",
            "4f90cacc464b4ea5907f4b4314d6ce90",
            "7f1f599ea871499eb48aab6c22e39194",
            "5444e753da524d00bcbc6a11372a1d05",
            "b9af2d3c97f941cd931dee1ea51fec82",
            "7bb7be693a4a4f7eaaf8956e426b59ae",
            "0723a67646334a4db06a7a5328aaad98",
            "f5591d94ea9f4613b1594a267f9b7b0c",
            "fd770a63bdbe45f8b06f64ddc855da27",
            "003621893dd14628944482195df2d790",
            "0641fd900e934c249ca1e99d76714a37",
            "64c9987cd01d48a792fc60d32fcfb332",
            "e92c8fe76e254a2fbbbd78691af36692",
            "f1ac15ee22f44bd5ba318138742845dc",
            "3de24106f2374f8a85c25105d41a6f61",
            "2a5a9cfc9cd8458a9f60569dc3ef4afc"
          ]
        },
        "id": "zWvCzZbJ6f2w",
        "outputId": "e4a0d587-cccd-4462-90e5-86fa99b3228b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad7ff7a7e36648c6baf26e50704632d9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous section, we explored the simplest of use cases: doing <font color='blue'>inference</font> on a <font color='blue'>single sequence</font> of a <font color='blue'>small length</font>. However, some questions emerge already:\n",
        "\n",
        "- How do we handle <font color='blue'>multiple sequences</font>?\n",
        "- How do we handle multiple sequences of <font color='blue'>different lengths</font>?\n",
        "- Are <font color='blue'>vocabulary indices</font> the <font color='blue'>only inputs</font> that allow a model to <font color='blue'>work well</font>?\n",
        "- Is there such a thing as <font color='blue'>too long</font> a <font color='blue'>sequence</font>?\n",
        "\n",
        "Let's see what kinds of problems these questions pose, and how we can solve them using the ðŸ¤— Transformers API."
      ],
      "metadata": {
        "id": "Fl8L9LID7aNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models expect a batch of inputs\n",
        "\n",
        "In the previous exercise you saw how <font color='blue'>sequences</font> get translated into <font color='blue'>lists of numbers</font>. Let's <font color='blue'>convert</font> this list of numbers to a <font color='blue'>tensor</font> and send it to the model:"
      ],
      "metadata": {
        "id": "doZl8HFO7iUI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2sU6pKr7ZIl",
        "outputId": "51472ca5-9c39-474c-a439-be63c2858eb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "too many indices for tensor of dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-32cb9a57c027>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m                                                   \u001b[0;31m# This is 1D tensor of shape [14] because we have 14 tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# This line will fail.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m         distilbert_output = self.distilbert(\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_if_padding_and_no_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mwarn_if_padding_and_no_attention_mask\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m   4687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4688\u001b[0m         \u001b[0;31m# Check only the first and last input IDs to reduce overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4689\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4690\u001b[0m             warn_string = (\n\u001b[1;32m   4691\u001b[0m                 \u001b[0;34m\"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n",
        "\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "input_ids = torch.tensor(ids)                                                   # This is 1D tensor of shape [14] because we have 14 tokens\n",
        "# This line will fail.\n",
        "model(input_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oh no! Why did this fail? We followed the steps from the pipeline in section 2!\n",
        "\n",
        "The problem is that we <font color='blue'>sent</font> a <font color='blue'>single sequence</font> to the model, whereas ðŸ¤— Transformers models <font color='blue'>expect multiple sentences</font> by <font color='blue'>default</font>. Here we tried to do everything the tokenizer did behind the scenes when we applied it to a sequence. But if you look closely, you'll see that the tokenizer didn't just convert the list of input IDs into a tensor, it <font color='blue'>added a dimension</font> on top of it:"
      ],
      "metadata": {
        "id": "LHTgLMRa7wwj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtMOtLPC7ZIm",
        "outputId": "f36c35a5-b27d-4747-a776-69f946a1d8bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
            "          2607,  2026,  2878,  2166,  1012,   102]])\n"
          ]
        }
      ],
      "source": [
        "tokenized_inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
        "print(tokenized_inputs[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examining what we ran before, we see that we passed a 1D tensor into the model."
      ],
      "metadata": {
        "id": "US6V1_LdBJkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The length of the list passed to the model\n",
        "len(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YaimEhi_D-E",
        "outputId": "6e62210e-3f4c-4618-a41c-2f6ea95ff2df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's fix this by <font color='blue'>adding a new dimension</font>:"
      ],
      "metadata": {
        "id": "H68Uq0wE71Ba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYl8fb9x7ZIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "479dbd28-93ca-48ae-c447-95d17c26bbc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of input ids:  torch.Size([1, 14])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n",
        "\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "input_ids = torch.tensor([ids])                                                 # This a 2D tensor of shape [1, 14], where 1 is the batch size (containing a single sequence) and 14 is the sequence length.\n",
        "print('Shape of input ids: ', input_ids.shape)\n",
        "output = model(input_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We print the input IDs as well as the resulting logits â€” here's the output:"
      ],
      "metadata": {
        "id": "yxRMMdm676Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input IDs:\", input_ids)\n",
        "print(\"Logits:\", output.logits)"
      ],
      "metadata": {
        "id": "2O4g-8WW77sM",
        "outputId": "f1934fed-b35a-4ec3-9d80-e9aae9046052",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs: tensor([[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n",
            "          2026,  2878,  2166,  1012]])\n",
            "Logits: tensor([[-2.7276,  2.8789]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>Batching</font> is the act of <font color='blue'>sending multiple sentences</font> through the <font color='blue'>model</font>, all at once. If you only have one sentence, you can just build a batch with a single sequence:"
      ],
      "metadata": {
        "id": "ROQ_Clqx7_qC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batched_ids = [ids, ids]\n",
        "batched_ids = torch.tensor(batched_ids)\n",
        "output = model(batched_ids)\n",
        "print(\"Input IDs:\", batched_ids)\n",
        "print(\"Logits:\", output.logits)"
      ],
      "metadata": {
        "id": "x_m1BoNQ8JQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ec666d8-e79f-460b-f544-403e6586d00b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs: tensor([[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n",
            "          2026,  2878,  2166,  1012],\n",
            "        [ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n",
            "          2026,  2878,  2166,  1012]])\n",
            "Logits: tensor([[-2.7276,  2.8789],\n",
            "        [-2.7276,  2.8789]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a batch of <font color='blue'>two identical sequences</font>!\n",
        "\n",
        "**Try it out!** Convert this `batched_ids` list into a tensor and pass it through your model. Check that you obtain the same logits as before (but twice)!"
      ],
      "metadata": {
        "id": "2I38HUEN8Ilu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise\n",
        "import numpy as np\n",
        "\n",
        "input_ids = torch.tensor(np.array(batched_ids))\n",
        "output = model(input_ids)\n",
        "print(\"Input IDs:\", input_ids)\n",
        "print(\"Logits:\", output.logits)"
      ],
      "metadata": {
        "id": "skV-v_To8ZD4",
        "outputId": "02ae33ca-6063-4c60-d50f-d4b98a172316",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs: tensor([[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n",
            "          2026,  2878,  2166,  1012],\n",
            "        [ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n",
            "          2026,  2878,  2166,  1012]])\n",
            "Logits: tensor([[-2.7276,  2.8789],\n",
            "        [-2.7276,  2.8789]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>Batching</font> allows the model to work when you <font color='blue'>feed it multiple sentences</font>. Using multiple sequences is just as simple as building a batch with a single sequence. There's a second issue, though. When you're trying to batch together <font color='blue'>two (or more) sentences</font>, they might be of <font color='blue'>different lengths</font>. If you've ever worked with tensors before, you know that they need to be of <font color='blue'>rectangular shape</font>, so you won't be able to convert the list of input IDs into a tensor directly. To work around this problem, we usually <font color='blue'>pad</font> the inputs."
      ],
      "metadata": {
        "id": "MV7L_1Xj8ZTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding the inputs\n",
        "\n",
        "The following list of lists <font color='blue'>cannot</font> be converted to a tensor:"
      ],
      "metadata": {
        "id": "LjxQC_a-8eXY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE_SUHra7ZIo"
      },
      "outputs": [],
      "source": [
        "batched_ids = [\n",
        "    [200, 200, 200],\n",
        "    [200, 200]\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to work around this, we'll use <font color='blue'>padding</font> to make our tensors have a <font color='blue'>rectangular shape</font>. Padding makes sure all our sentences have the <font color='blue'>same length</font> by adding a <font color='blue'>special word</font> called the <font color='blue'>padding token</font> to the <font color='blue'>sentences</font> with <font color='blue'>fewer values</font>. For example, if you have 10 sentences with 10 words and 1 sentence with 20 words, padding will ensure all the sentences have 20 words. In our example, the resulting tensor looks like this:"
      ],
      "metadata": {
        "id": "1guaBYba8iMy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZFJOAcS7ZIo"
      },
      "outputs": [],
      "source": [
        "padding_id = 100\n",
        "\n",
        "batched_ids = [\n",
        "    [200, 200, 200],\n",
        "    [200, 200, padding_id],\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The <font color='blue'>padding token ID</font> can be found in <font color='blue'>tokenizer.pad_token_id</font>. Let's use it and send our two sentences through the model individually and batched together:"
      ],
      "metadata": {
        "id": "ixLzTEH08tof"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R__W9viW7ZIo",
        "outputId": "ef0aa72f-4440-449b-dce0-929409a75ece",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.5694, -1.3895]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 0.5803, -0.4125]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 1.5694, -1.3895],\n",
            "        [ 1.3374, -1.2163]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sequence1_ids = [[200, 200, 200]]\n",
        "sequence2_ids = [[200, 200]]\n",
        "batched_ids = [\n",
        "    [200, 200, 200],\n",
        "    [200, 200, tokenizer.pad_token_id],\n",
        "]\n",
        "\n",
        "print(model(torch.tensor(sequence1_ids)).logits)\n",
        "print(model(torch.tensor(sequence2_ids)).logits)\n",
        "print(model(torch.tensor(batched_ids)).logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's <font color='blue'>something wrong</font> with the <font color='blue'>logits in our batched predictions</font>: the <font color='blue'>second row</font> should be the <font color='blue'>same</font> as the <font color='blue'>logits</font> for the second sentence, but we've got completely different values!\n",
        "\n",
        "This is because the <font color='blue'>key feature</font> of <font color='blue'>Transformer models</font> is <font color='blue'>attention</font> layers that <font color='blue'>contextualize</font> each <font color='blue'>token</font>. These will <font color='blue'>take into account</font> the <font color='blue'>padding tokens</font> since they attend to all of the tokens of a sequence. To get the same result when passing individual sentences of different lengths through the model or when passing a batch with the same sentences and padding applied, we need to <font color='blue'>tell</font> those <font color='blue'>attention layers</font> to <font color='blue'>ignore</font> the <font color='blue'>padding tokens</font>. This is done by using an <font color='blue'>attention mask</font>."
      ],
      "metadata": {
        "id": "2tofOaG_8yfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention masks\n",
        "\n",
        "<font color='blue'>Attention masks</font> are tensors with the <font color='blue'>exact same shape</font> as the <font color='blue'>input IDs tensor</font>, filled with 0s and 1s: <font color='blue'>1s</font> indicate the corresponding tokens <font color='blue'>should</font> be attended to, and 0s indicate the corresponding tokens <font color='blue'>should not</font> be attended to (i.e., they <font color='blue'>should be ignored</font> by the attention layers of the model).\n",
        "\n",
        "Letâ€™s complete the previous example with an attention mask:"
      ],
      "metadata": {
        "id": "tv4r49_K85nm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6OOw5x97ZIp",
        "outputId": "b0171073-6cfd-4bfc-e307-634d57476c10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.5694, -1.3895],\n",
            "        [ 0.5803, -0.4125]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "batched_ids = [\n",
        "    [200, 200, 200],\n",
        "    [200, 200, tokenizer.pad_token_id],\n",
        "]\n",
        "\n",
        "attention_mask = [\n",
        "    [1, 1, 1],\n",
        "    [1, 1, 0],\n",
        "]\n",
        "\n",
        "outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))\n",
        "print(outputs.logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we get the same logits for the second sentence in the batch. Notice how the <font color='blue'>last value</font> of the <font color='blue'>second sequence</font> is a <font color='blue'>padding ID</font>, which is a 0 value in the attention mask."
      ],
      "metadata": {
        "id": "IXU5izL19D4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try it out!** Apply the <font color='blue'>tokenization manually</font> on the <font color='blue'>two sentences</font> used in <font color='blue'>section 2</font> :\n",
        "\n",
        "- I've been waiting for a HuggingFace course my whole life.\n",
        "- I hate this so much!.\n",
        "\n",
        "Pass them through the model and <font color='blue'>check</font> that you get the <font color='blue'>same logits</font> as in <font color='blue'>section 2</font>. Now <font color='blue'>batch them together</font> using the <font color='blue'>padding token</font>, then create the proper <font color='blue'>attention mask</font>. Check that you obtain the same results when going through the model!"
      ],
      "metadata": {
        "id": "pS-Wbtbl9HYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the approach taken in Section 2:"
      ],
      "metadata": {
        "id": "n9CCcwpnFPfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 2 Code\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sentences = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\"\n",
        "]\n",
        "\n",
        "# Tokenize and convert to IDs\n",
        "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Extract the token IDs and attention masks\n",
        "input_ids = inputs[\"input_ids\"]\n",
        "attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "# Input IDs for each sentence\n",
        "print(input_ids[0])\n",
        "print(input_ids[1])\n",
        "\n",
        "# Padding in the attention masks\n",
        "print(attention_mask[0])\n",
        "print(attention_mask[1])\n",
        "\n",
        "# Pass the tokenized inputs through the model\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# Print the logits for each sentence\n",
        "print(outputs.logits)"
      ],
      "metadata": {
        "id": "DabO_UclCmFY",
        "outputId": "a24d1ee5-ce15-46dc-e32c-130ba38e3626",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
            "         2607,  2026,  2878,  2166,  1012,   102])\n",
            "tensor([ 101, 1045, 5223, 2023, 2061, 2172,  999,  102,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([[-1.5607,  1.6123],\n",
            "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, we may follow the approach described in this section:"
      ],
      "metadata": {
        "id": "PRU00TdPFSk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise Code\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "tokenizer.pad_token_id\n",
        "sentences = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\"\n",
        "]\n",
        "\n",
        "# Tokenize sentences, add special tokens (e.g., [CLS], [SEP]), and convert to IDs\n",
        "tokens = [tokenizer.tokenize(sentence, add_special_tokens=True) for sentence in sentences]\n",
        "ids = [tokenizer.convert_tokens_to_ids(token) for token in tokens]\n",
        "\n",
        "# Print the sentences and corresponding token IDs\n",
        "for sentence, id_list in zip(sentences, ids):\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Token IDs: {id_list}\")"
      ],
      "metadata": {
        "id": "3Hv9h__e9MJN",
        "outputId": "d9086930-9674-45e2-99b7-ff904086d278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: I've been waiting for a HuggingFace course my whole life.\n",
            "Token IDs: [101, 1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012, 102]\n",
            "Sentence: I hate this so much!\n",
            "Token IDs: [101, 1045, 5223, 2023, 2061, 2172, 999, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise Code\n",
        "\n",
        "# Determine the maximum sequence length\n",
        "max_sequence_length = max(len(seq) for seq in ids)\n",
        "\n",
        "# Pad all sequences to the maximum length\n",
        "padded_ids = [seq + [tokenizer.pad_token_id] * (max_sequence_length - len(seq)) for seq in ids]\n",
        "\n",
        "# Create attention masks (1 for real tokens, 0 for padded tokens)\n",
        "attention_mask = [[1] * len(seq) + [0] * (max_sequence_length - len(seq)) for seq in ids]\n",
        "\n",
        "# Print the padded sequences and corresponding attention masks\n",
        "for padded_seq, att_mask in zip(padded_ids, attention_mask):\n",
        "    print(f\"Padded Sequence: {padded_seq}\")\n",
        "    print(f\"Attention Mask: {att_mask}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYIvXfFbe_Cb",
        "outputId": "918d243b-0199-4fa1-e54e-4a404f98e919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded Sequence: [101, 1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012, 102]\n",
            "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Padded Sequence: [101, 1045, 5223, 2023, 2061, 2172, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise Code\n",
        "\n",
        "# Convert (the list of) IDs and masks to tensors for model input\n",
        "input_ids = torch.tensor(padded_ids)\n",
        "attention_mask_tensor = torch.tensor(attention_mask)\n",
        "\n",
        "# Pass inputs through the model and get logits\n",
        "batched_outputs = model(input_ids, attention_mask=attention_mask_tensor)\n",
        "\n",
        "# Print logits\n",
        "print(batched_outputs.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEBb3AxIhFKn",
        "outputId": "ff29e23f-49b6-44e8-c757-33aa708e1915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.5607,  1.6123],\n",
            "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Longer sequences\n",
        "\n",
        "With Transformer models, there is a <font color='blue'>limit to the lengths</font> of the <font color='blue'>sequences</font> we can pass the models. Most models handle sequences of up to 512 or 1024 tokens, and will crash when asked to process longer sequences. There are two solutions to this problem:\n",
        "\n",
        "- Use a model with a <font color='blue'>longer supported</font> sequence length.\n",
        "- <font color='blue'>Truncate</font> your sequences.\n",
        "\n",
        "Models have different supported sequence lengths, and some specialize in handling very long sequences. [Longformer](https://huggingface.co/docs/transformers/model_doc/longformer) is one example, and another is [LED](https://huggingface.co/docs/transformers/model_doc/led). If you're working on a task that requires very long sequences, we recommend you take a look at those models."
      ],
      "metadata": {
        "id": "aqaPnnJZ9OPF"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ad7ff7a7e36648c6baf26e50704632d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9af2d3c97f941cd931dee1ea51fec82",
              "IPY_MODEL_7bb7be693a4a4f7eaaf8956e426b59ae",
              "IPY_MODEL_0723a67646334a4db06a7a5328aaad98",
              "IPY_MODEL_f5591d94ea9f4613b1594a267f9b7b0c"
            ],
            "layout": "IPY_MODEL_545de1b009ff4712a290efcb13806b66"
          }
        },
        "6990019b41794d03aebacac331aa8787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b45018ef4ad408b8d3d8ab564a6dd8f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7ac9da6bc1764e45b30a31e865da6c7e",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "dae49bad1bca4088a94294c9a618b5c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1a276d0918c3402ab3aa15b706dc1134",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bedca7f2962a41dda9a3c596011834c4",
            "value": ""
          }
        },
        "6909081054ad4e86817483d913dfa893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_2c481a9a36194d29925108221220cc5a",
            "style": "IPY_MODEL_b97af72cbbf24b8cbfec9dbc67184470",
            "value": true
          }
        },
        "f4d93b25c07c4d00a9e9f8ca82b14a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_e01d14f74dc04d08af9f9a919f9fbca6",
            "style": "IPY_MODEL_da235c328ddf4541a978aae5a6385a48",
            "tooltip": ""
          }
        },
        "e31ceb7bff05434f847e6d75120fc490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef85ec37754e4d9093927294da7ac0dc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_84bdd411665a448293472988b7e54683",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "545de1b009ff4712a290efcb13806b66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "3b45018ef4ad408b8d3d8ab564a6dd8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ac9da6bc1764e45b30a31e865da6c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a276d0918c3402ab3aa15b706dc1134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bedca7f2962a41dda9a3c596011834c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c481a9a36194d29925108221220cc5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b97af72cbbf24b8cbfec9dbc67184470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e01d14f74dc04d08af9f9a919f9fbca6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da235c328ddf4541a978aae5a6385a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ef85ec37754e4d9093927294da7ac0dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84bdd411665a448293472988b7e54683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f90cacc464b4ea5907f4b4314d6ce90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f1f599ea871499eb48aab6c22e39194",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5444e753da524d00bcbc6a11372a1d05",
            "value": "Connecting..."
          }
        },
        "7f1f599ea871499eb48aab6c22e39194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5444e753da524d00bcbc6a11372a1d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9af2d3c97f941cd931dee1ea51fec82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd770a63bdbe45f8b06f64ddc855da27",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_003621893dd14628944482195df2d790",
            "value": "Token is valid (permission: write)."
          }
        },
        "7bb7be693a4a4f7eaaf8956e426b59ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0641fd900e934c249ca1e99d76714a37",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_64c9987cd01d48a792fc60d32fcfb332",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "0723a67646334a4db06a7a5328aaad98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e92c8fe76e254a2fbbbd78691af36692",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f1ac15ee22f44bd5ba318138742845dc",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "f5591d94ea9f4613b1594a267f9b7b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3de24106f2374f8a85c25105d41a6f61",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2a5a9cfc9cd8458a9f60569dc3ef4afc",
            "value": "Login successful"
          }
        },
        "fd770a63bdbe45f8b06f64ddc855da27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "003621893dd14628944482195df2d790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0641fd900e934c249ca1e99d76714a37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64c9987cd01d48a792fc60d32fcfb332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e92c8fe76e254a2fbbbd78691af36692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1ac15ee22f44bd5ba318138742845dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3de24106f2374f8a85c25105d41a6f61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a5a9cfc9cd8458a9f60569dc3ef4afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}