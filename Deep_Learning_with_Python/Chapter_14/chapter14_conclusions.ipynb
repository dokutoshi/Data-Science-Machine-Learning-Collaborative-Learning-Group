{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSpGT_cTYMxV"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and a lot of edits made by Matthew Kehoe.\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxUaTrMFYMxW"
      },
      "source": [
        "# Conclusions\n",
        "\n",
        "You've almost reached the end of this book. This last chapter will summarize and review core concepts while also expanding your horizons beyond what you've learned so far. Becoming an effective AI practitioner is a journey, and finishing this book is merely your first step on it. I want to make sure you realize this and are properly equipped to take the next steps of this journey on your own.\n",
        "\n",
        "We'll start with a bird's-eye view of what you should take away from this book. This should refresh your memory regarding some of the concepts you've learned. Next, I'll present an overview of some key limitations of deep learning. To use a tool appropriately, you should not only understand what it **can** do but also be aware of what it **can't** do. Finally, I'll offer some speculative thoughts about the future evolution of deep learning, machine learning, and AI. This should be especially interesting to you if you'd like to get into fundamental research. The chapter\n",
        "ends with a short list of resources and strategies for further learning about machine learning and staying up to date with new advances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MLy7FOMYMxX"
      },
      "source": [
        "## Key concepts in review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uqn1RVLAYMxX"
      },
      "source": [
        "### Various approaches to AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7gnQ7ZGYMxX"
      },
      "source": [
        "### What makes deep learning special within the field of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyRFIZc0YMxX"
      },
      "source": [
        "### How to think about deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub47w1AWYMxY"
      },
      "source": [
        "### Key enabling technologies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwqrcEo2YMxY"
      },
      "source": [
        "### The universal machine-learning workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NQ_u6-OYMxY"
      },
      "source": [
        "### Key network architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uMWppQqYMxZ"
      },
      "source": [
        "#### Densely connected networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hj22H6sjYMxZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "inputs = keras.Input(shape=(num_input_features,))\n",
        "x = layers.Dense(32, activation=\"relu\")(inputs)\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nonBJcBhYMxa"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(num_input_features,))\n",
        "x = layers.Dense(32, activation=\"relu\")(inputs)\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-bnvCvpYMxb"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(num_input_features,))\n",
        "x = layers.Dense(32, activation=\"relu\")(inputs)\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPrhIgJJYMxb"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(num_input_features,))\n",
        "x = layers.Dense(32, activation=\"relu\")(inputs)\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "outputs layers.Dense(num_values)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ljuW-xVYMxc"
      },
      "source": [
        "#### Convnets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzilRLkSYMxc"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(height, width, channels))\n",
        "x = layers.SeparableConv2D(32, 3, activation=\"relu\")(inputs)\n",
        "x = layers.SeparableConv2D(64, 3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "x = layers.SeparableConv2D(64, 3, activation=\"relu\")(x)\n",
        "x = layers.SeparableConv2D(128, 3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "x = layers.SeparableConv2D(64, 3, activation=\"relu\")(x)\n",
        "x = layers.SeparableConv2D(128, 3, activation=\"relu\")(x)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2YW64bFYMxc"
      },
      "source": [
        "#### RNNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atTIzxRpYMxc"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(num_timesteps, num_features))\n",
        "x = layers.LSTM(32)(inputs)\n",
        "outputs = layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHIFfoarYMxd"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(num_timesteps, num_features))\n",
        "x = layers.LSTM(32, return_sequences=True)(inputs)\n",
        "x = layers.LSTM(32, return_sequences=True)(x)\n",
        "x = layers.LSTM(32)(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6-qqeI-YMxd"
      },
      "source": [
        "#### Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO2a0GRUYMxd"
      },
      "outputs": [],
      "source": [
        "encoder_inputs = keras.Input(shape=(sequence_length,), dtype=\"int64\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "transformer.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsRIbUvYYMxd"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(sequence_length,), dtype=\"int64\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN_PW3aTYMxd"
      },
      "source": [
        "### The space of possibilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qayVCxBYMxe"
      },
      "source": [
        "## The limitations of deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnYFdnUbYMxe"
      },
      "source": [
        "### The risk of anthropomorphizing machine-learning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9lFWUElYMxe"
      },
      "source": [
        "### Automatons vs. intelligent agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q_D1hL0YMxe"
      },
      "source": [
        "### Local generalization vs. extreme generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHpxDxZFYMxe"
      },
      "source": [
        "### The purpose of intelligence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANNf9GC9YMxf"
      },
      "source": [
        "### Climbing the spectrum of generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xr3IvXWYMxf"
      },
      "source": [
        "## Setting the course toward greater generality in AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SXWJbNXYMxf"
      },
      "source": [
        "### On the importance of setting the right objective: The shortcut rule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbH6YZ59YMxf"
      },
      "source": [
        "### A new target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRWy2TMvYMxf"
      },
      "source": [
        "## Implementing intelligence: The missing ingredients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nch2SKRtYMxf"
      },
      "source": [
        "### Intelligence as sensitivity to abstract analogies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMaaYr6BYMxf"
      },
      "source": [
        "### The two poles of abstraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVTjwPLnYMxf"
      },
      "source": [
        "#### Value-centric analogy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHVO9eGWYMxf"
      },
      "source": [
        "#### Program-centric analogy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WTNM_ZoYMxg"
      },
      "source": [
        "#### Cognition as a combination of both kinds of abstraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EU6R0ZZYMxg"
      },
      "source": [
        "### The missing half of the picture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuD29Wq7YMxg"
      },
      "source": [
        "## The future of deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXJoDfsuYMxg"
      },
      "source": [
        "### Models as programs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tedihIjRYMxg"
      },
      "source": [
        "### Blending together deep learning and program synthesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpw8pu-GYMxg"
      },
      "source": [
        "#### Integrating deep-learning modules and algorithmic modules into hybrid systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U52CTmWPYMxh"
      },
      "source": [
        "#### Using deep learning to guide program search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPW1cjWIYMxh"
      },
      "source": [
        "### Lifelong learning and modular subroutine reuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txS0bC5vYMxh"
      },
      "source": [
        "### The long-term vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhJ2K82kYMxh"
      },
      "source": [
        "## Staying up to date in a fast-moving field"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FcrRHH5YMxh"
      },
      "source": [
        "### Practice on real-world problems using Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr59DgjyYMxh"
      },
      "source": [
        "### Read about the latest developments on arXiv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ASBIxJ9YMxi"
      },
      "source": [
        "### Explore the Keras ecosystem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DVEsWT2YMxi"
      },
      "source": [
        "## Final words"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "chapter14_conclusions.i",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}