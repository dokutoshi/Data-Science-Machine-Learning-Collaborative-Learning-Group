{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewshawnkehoe/Machine-Learning-in-Python/blob/main/Chapter_13/chapter13_best_practices_for_the_real_world.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMPSgXP7C_mK"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it contains text, runnable code blocks, section titles, and a bunch of edits made by Matthew Kehoe.\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z3t0kumC_mN"
      },
      "source": [
        "# Best practices for the real world\n",
        "\n",
        "You've come far since the beginning of this book. You can now train image classification models, image segmentation models, models for classification or regression on vector data, timeseries forecasting models, text-classification models, sequence-to-sequence models, and even generative models for text and images. You've got all\n",
        "the bases covered.\n",
        "\n",
        "However,  your  models  so  far  have  all  been  trained  at  a   <font color='blue'>small  scale</font>—on  small datasets,  with  a  single  GPU—and  they  generally  haven't  reached  the  best  achievable performance on each dataset we looked at. This book is, after all, an introductory book. If you are to go out in the <font color='blue'>real world</font> and achieve <font color='blue'>state-of-the-art results</font> on brand new problems, there's still a bit of a chasm that you'll need to cross.\n",
        "  \n",
        "This  penultimate  chapter  is  about  bridging  that  gap  and  giving  you  the  best practices  you'll  need  as  you  go  from <font color='blue'>machine  learning  student</font>  to  fully fledged <font color='blue'>machine learning engineer</font>. We'll review essential techniques for systematically improving  model  performance:  <font color='blue'>hyperparameter  tuning</font>  and <font color='blue'>model  ensembling</font>.  Then we'll look at how you can speed up and scale up model training, with <font color='blue'>multi-GPU</font> and <font color='blue'>TPU</font> training, mixed precision, and leveraging remote computing resources in the cloud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7MS1LdkC_mO"
      },
      "source": [
        "## Getting the most out of your models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Blindly  trying  out  different  architecture  configurations  works  well  enough  if  you just need something that works okay. In this section, we'll go beyond \"works okay\" to <font color='blue'>works  great  and  wins  machine  learning  competitions</font> via  a  set  of  must-know techniques for building state-of-the-art deep learning models."
      ],
      "metadata": {
        "id": "cWJ1dSrGDnIj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBiCesg5C_mO"
      },
      "source": [
        "### Hyperparameter optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When  building  a  deep  learning  model,  you  have  to  make  many  seemingly  arbitrary decisions: How many layers should you stack? How many units or filters should go in each layer? Should you use `relu` as activation, or a different function? Should you use `BatchNormalization` after a given layer? How much dropout should you use? And so on. These <font color='blue'>architecture-level parameters</font> are called `hyperparameters` to distinguish them from the `parameters` of a model, which are <font color='blue'>trained via backpropagation</font>.\n",
        "\n",
        "In practice, experienced machine learning engineers and researchers <font color='blue'>build intuition  over  time</font>  as  to  what  works  and  what  doesn't  when  it  comes  to these  choices— they develop hyperparameter-tuning skills. But <font color='blue'>there are no formal rules</font>. If you want to get to the very limit of what can be achieved on a given task, you can't be content with such arbitrary choices. Your <font color='blue'>initial decisions are almost always suboptimal</font>, even if you have very good intuition. You can refine your choices by tweaking them by hand and  retraining  the  model  repeatedly—that's  what  machine  learning  engineers  and researchers spend most of their time doing. But it shouldn't be your job as a human to fiddle with hyperparameters all day—that is better left to a machine.\n",
        "\n",
        "Thus you need to explore the space of possible decisions automatically, systematically, in a principled way. You need to <font color='blue'>search the architecture space</font> and find the best-performing architectures <font color='blue'>empirically</font>. That's what the field of <font color='blue'>automatic hyperparameter optimization</font> is about: it's an entire field of research, and an important one.\n",
        "\n",
        "The process of optimizing hyperparameters typically looks like this:\n",
        "\n",
        "1. Choose a set of hyperparameters (automatically).\n",
        "2. Build the corresponding model.\n",
        "3. Fit it to your training data, and measure performance on the validation data.\n",
        "4. Choose the next set of hyperparameters to try (automatically).\n",
        "5. Repeat.\n",
        "6. Eventually, measure performance on your test data.\n",
        "\n",
        "The key to this process is the algorithm that analyzes the relationship between <font color='blue'>validation  performance</font>  and  various  <font color='blue'>hyperparameter  values</font>  to  choose  the  next  set  of hyperparameters to evaluate. Many different techniques are possible: Bayesian optimization, genetic algorithms, simple random search, and so on.\n",
        "\n",
        "Training the weights of a model is relatively easy: you compute a <font color='blue'>loss function</font> on a <font color='blue'>mini-batch</font>  of  data  and  then  use  <font color='blue'>backpropagation</font>  to  move  the  weights  in  the  right direction. Updating hyperparameters, on the other hand, presents unique challenges.\n",
        "\n",
        "Consider these points:\n",
        "\n",
        "* The  <font color='blue'>hyperparameter  space</font> is  typically  made  up  of  <font color='blue'>discrete  decisions</font>  and thus isn't continuous or differentiable. Hence, you typically <font color='blue'>can't do gradient descent</font> in hyperparameter space. Instead, you must rely on <font color='blue'>gradient-free optimization techniques</font>, which naturally are far less efficient than gradient descent.\n",
        "* Computing  the  feedback  signal  of  this  optimization  process  (does  this  set  of hyperparameters lead to a high-performing model on this task?) can be <font color='blue'>extremely expensive</font>: it requires creating and training a new model from scratch on your dataset.\n",
        "* The feedback signal may be <font color='blue'>noisy</font>: if a training run performs 0.2% better, is that because of a better model configuration, or because you got lucky with the initial weight values?\n",
        "\n",
        "Thankfully, there's  a  tool  that  makes  hyperparameter  tuning  simpler:  <font color='blue'>KerasTuner</font>. Let's check it out."
      ],
      "metadata": {
        "id": "cbMq_YYPD0Uh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ3CkWreC_mP"
      },
      "source": [
        "#### Using KerasTuner\n",
        "\n",
        "Let's start by installing KerasTuner:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzpdIF9KC_mP",
        "outputId": "f3aa55c1-66f8-4049-d154-e1f2be9bfd47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/129.1 kB\u001b[0m \u001b[31m543.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m112.6/129.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KerasTuner  lets  you  replace  <font color='blue'>hard-coded  hyperparameter  values</font>,  such  as  `units=32`, with a <font color='blue'>range of possible choices</font>, such as `Int(name=\"units\", min_value=16,max_value=64, step=16)`. This <font color='blue'>set of choices</font> in a given model is called the <font color='blue'>search space</font> of the hyperparameter tuning process.\n",
        "\n",
        "To specify a search space, define a model-building function (see the listing below). It  takes  an  <font color='blue'>hp  argument</font>,  from  which  you  can  sample  hyperparameter  ranges,  and  it returns a compiled Keras model."
      ],
      "metadata": {
        "id": "IsfitACeFLl8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8MJO2koC_mR"
      },
      "source": [
        "**A KerasTuner model-building function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7juwTy4UC_mR"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_model(hp):\n",
        "    units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)           # Sample hyperparameter values from the hp object. After sampling, these values\n",
        "    model = keras.Sequential([                                                  # (such as the \"units\" variable here) are just regular Python constants.\n",
        "        layers.Dense(units, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])         # Different kinds of hyperparameters are available: Int, Float, Boolean, Choice.\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"])\n",
        "    return model                                                                # The function returns a compiled model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to adopt a more <font color='blue'>modular</font> and configurable <font color='blue'>approach</font> to model-building,\n",
        "you can also subclass the `HyperModel` class and define a `build` method, as follows."
      ],
      "metadata": {
        "id": "4CUfmtReGEHj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "145NSfZMC_mS"
      },
      "source": [
        "**A KerasTuner `HyperModel`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SPKWmkCC_mT"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "class SimpleMLP(kt.HyperModel):\n",
        "    def __init__(self, num_classes):                                            # Thanks to the object-oriented approach, we can configure model constants as\n",
        "        self.num_classes = num_classes                                          # constructor arguments (instead of hardcoding them in the model-building function).\n",
        "\n",
        "    def build(self, hp):                                                        # The build() method is identical to our prior  build_model() standalone function.\n",
        "        units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
        "        model = keras.Sequential([\n",
        "            layers.Dense(units, activation=\"relu\"),\n",
        "            layers.Dense(self.num_classes, activation=\"softmax\")\n",
        "        ])\n",
        "        optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
        "        model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"])\n",
        "        return model\n",
        "\n",
        "hypermodel = SimpleMLP(num_classes=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to define a <font color='blue'>tuner</font>. Schematically, you can think of a tuner as a <font color='blue'>for loop</font> that will repeatedly\n",
        "\n",
        "* Pick a set of hyperparameter values\n",
        "* Call the model-building function with these values to create a model\n",
        "* Train the model and record its metrics\n",
        "\n",
        "KerasTuner has several built-in tuners available—`RandomSearch`, `BayesianOptimization`, and `Hyperband`. Let's try `BayesianOptimization`, a tuner that attempts to make smart <font color='blue'>predictions</font>  for  which  <font color='blue'>new hyperparameter  values</font>  are  likely  to  perform  best given the outcomes of previous choices:"
      ],
      "metadata": {
        "id": "CCPLdsTHG65a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx10dsb_C_mU"
      },
      "outputs": [],
      "source": [
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,                                                                # Specify the model-building function (or hyper-model instance).\n",
        "    objective=\"val_accuracy\",                                                   # Specify the metric that the tuner will seek to optimize. Always specify validation metrics,\n",
        "                                                                                # since the goal of the search process is to find models that generalize!\n",
        "    max_trials=100,                                                             # Maximum number of different model configurations (“trials”) to try before ending the search.\n",
        "    executions_per_trial=2,                                                     # To reduce metrics variance, you can train the same model multiple times and average the results.\n",
        "                                                                                # executions_per_trial is how many training rounds (executions) to run for each model configuration (trial).\n",
        "    directory=\"mnist_kt_test\",                                                  # Where to store the search logs.\n",
        "    overwrite=True,                                                             # Whether to overwrite data in directory to start a new search. Set this to True if you’ve modified\n",
        "                                                                                # the model-building function, or to False to resume a previously started search with the same\n",
        "                                                                                # model-building function.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can display an overview of the search space via `search_space_summary()`:"
      ],
      "metadata": {
        "id": "X1fVlDBOHvWH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4yXbUH9C_mV",
        "outputId": "c8e64ad3-e9a6-4d4b-9af4-5715d2e26287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 2\n",
            "units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': 'linear'}\n",
            "optimizer (Choice)\n",
            "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}\n"
          ]
        }
      ],
      "source": [
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective maximization and minimization\n",
        "For built-in metrics (like accuracy, in our case), the *direction* of the metric (<font color='blue'>accuracy</font> should  be  <font color='blue'>maximized</font>,  but  a  <font color='blue'>loss</font>  should  be <font color='blue'>minimized</font>)  is  inferred  by  KerasTuner. However, for a custom metric, you should specify it yourself, like this:"
      ],
      "metadata": {
        "id": "9TqYKbkMIoC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pseudocode\n",
        "objective = kt.Objective(\n",
        "    name=\"val_accuracy\",                                                        # The metric’s name, as found in epoch logs\n",
        "    direction=\"max\")                                                            # The metric’s desired direction: \"min\" or \"max\"\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective=objective,\n",
        "    ...\n",
        ")"
      ],
      "metadata": {
        "id": "Fy9amhqiI2vk",
        "outputId": "f98954ec-9eb4-4812-b9aa-1f61e49c7dc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "positional argument follows keyword argument (<ipython-input-6-87b81cd4278e>, line 9)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-87b81cd4278e>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    )\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's launch the search. Don't forget to <font color='blue'>pass validation data</font>, and make sure <font color='blue'>not to use your test set as validation data</font>—otherwise you'd quickly start overfitting to your test data, and you wouldn't be able to trust your test metrics anymore:"
      ],
      "metadata": {
        "id": "Yh9vk9-BJLuM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7HhghJQC_mW",
        "outputId": "b443071b-07c3-431f-9ed5-66bf79c37168",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 100 Complete [00h 01m 00s]\n",
            "val_accuracy: 0.9754499793052673\n",
            "\n",
            "Best val_accuracy So Far: 0.9769999980926514\n",
            "Total elapsed time: 01h 56m 13s\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
        "x_test = x_test.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
        "x_train_full = x_train[:]                                                       # Reserve for later\n",
        "y_train_full = y_train[:]                                                       # Reserve for later\n",
        "num_val_samples = 10000\n",
        "x_train, x_val = x_train[:-num_val_samples], x_train[-num_val_samples:]         # Set aside as a validation set\n",
        "y_train, y_val = y_train[:-num_val_samples], y_train[-num_val_samples:]         # Set aside as a validation set\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),              # Use an EarlyStopping callback to stop training when you start overfitting\n",
        "]\n",
        "tuner.search(                                                                   # This takes the same arguments as fit() (it simply passes them down to fit() for each new model).\n",
        "    x_train, y_train,\n",
        "    batch_size=128,\n",
        "    epochs=80,                                                                 # Use a large number of epochs (you don’t know in advance how many epochs each model will need)\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The  preceding  example  will  run  in  <font color='blue'>just  a  few  minutes</font>,  since  we're  only  looking  at  a few  possible  choices  and  we're  training  on  MNIST.  However,  with  a  typical  search space  and  dataset,  you'll  often  find  yourself  letting  the  <font color='blue'>hyperparameter  search  run overnight  or  even  over  several  days</font>.  If  your  search  process  crashes,  you  can  always restart  it—just  specify `overwrite=False`  in  the  tuner  so  that  it  can  resume  from the trial logs stored on disk.\n",
        "\n",
        "Once  the  search  is  complete,  you  can  <font color='blue'>query  the  best  hyperparameter  configurations</font>, which you can use to create high-performing models that you can then retrain."
      ],
      "metadata": {
        "id": "Nog8yZ67KQ90"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrkkSB2fC_mW"
      },
      "source": [
        "**Querying the best hyperparameter configurations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDpkZPYtC_mW"
      },
      "outputs": [],
      "source": [
        "top_n = 4\n",
        "best_hps = tuner.get_best_hyperparameters(top_n)                                # Returns a list of HyperParameter objects, which you can pass to the model-building function"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually, when <font color='blue'>retraining</font> these models, you may want to include the <font color='blue'>validation data</font> as <font color='blue'>part  of  the  training  data</font>,  since  you  won't  be  making  any  further  hyperparameter changes,  and  thus  you  will  no  longer  be   evaluating  performance  on  the  validation data.  In  our  example, we'd  train  these  final  models  on  the  totality  of  the  original\n",
        "MNIST training data, without reserving a validation set.\n",
        "\n",
        "Before we can train on the full training data, though, there's one last parameter we need to settle: the <font color='blue'>optimal number of epochs to train for</font>. Typically, you'll want to train the  new  models  for  longer  than  you  did  during  the  search:  using  an  aggressive `patience` value in the `EarlyStopping` callback saves time during the search, but it may lead to under-fit models. Just <font color='blue'>use the validation set</font> to find the <font color='blue'>best epoch</font>:"
      ],
      "metadata": {
        "id": "Isz7Pv2rKrO3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApJNfpiqC_mX"
      },
      "outputs": [],
      "source": [
        "def get_best_epoch(hp):\n",
        "    model = build_model(hp)\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            monitor=\"val_loss\", mode=\"min\", patience=10)                        # Note the high patience value\n",
        "    ]\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        validation_data=(x_val, y_val),\n",
        "        epochs=100,\n",
        "        batch_size=128,\n",
        "        callbacks=callbacks)\n",
        "    val_loss_per_epoch = history.history[\"val_loss\"]\n",
        "    best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
        "    print(f\"Best epoch: {best_epoch}\")\n",
        "    return best_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, <font color='blue'>train  on  the  full  dataset</font>  for  just  a  bit  longer  than  this  epoch  count, since you're training on more data; 20% more in this case:"
      ],
      "metadata": {
        "id": "-lre9aQLLPUk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn2yqDY7C_mX",
        "outputId": "9c5f3637-2eaf-49c6-ea98-51028be47820",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.4201 - accuracy: 0.8858 - val_loss: 0.2350 - val_accuracy: 0.9354\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.2201 - accuracy: 0.9372 - val_loss: 0.1800 - val_accuracy: 0.9528\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1701 - accuracy: 0.9513 - val_loss: 0.1568 - val_accuracy: 0.9562\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1402 - accuracy: 0.9596 - val_loss: 0.1350 - val_accuracy: 0.9629\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.1198 - accuracy: 0.9649 - val_loss: 0.1226 - val_accuracy: 0.9654\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1032 - accuracy: 0.9699 - val_loss: 0.1158 - val_accuracy: 0.9663\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.0920 - accuracy: 0.9739 - val_loss: 0.1092 - val_accuracy: 0.9681\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0816 - accuracy: 0.9765 - val_loss: 0.1053 - val_accuracy: 0.9692\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0737 - accuracy: 0.9787 - val_loss: 0.1028 - val_accuracy: 0.9718\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0672 - accuracy: 0.9813 - val_loss: 0.0964 - val_accuracy: 0.9735\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0611 - accuracy: 0.9828 - val_loss: 0.1000 - val_accuracy: 0.9723\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0561 - accuracy: 0.9839 - val_loss: 0.0997 - val_accuracy: 0.9720\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0511 - accuracy: 0.9859 - val_loss: 0.0962 - val_accuracy: 0.9728\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0471 - accuracy: 0.9867 - val_loss: 0.0924 - val_accuracy: 0.9750\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0431 - accuracy: 0.9875 - val_loss: 0.0970 - val_accuracy: 0.9733\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0400 - accuracy: 0.9885 - val_loss: 0.0943 - val_accuracy: 0.9742\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0365 - accuracy: 0.9899 - val_loss: 0.0933 - val_accuracy: 0.9748\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9905 - val_loss: 0.0906 - val_accuracy: 0.9763\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0314 - accuracy: 0.9916 - val_loss: 0.0946 - val_accuracy: 0.9751\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9924 - val_loss: 0.0939 - val_accuracy: 0.9751\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0265 - accuracy: 0.9932 - val_loss: 0.0963 - val_accuracy: 0.9754\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.0242 - accuracy: 0.9937 - val_loss: 0.0995 - val_accuracy: 0.9753\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.0990 - val_accuracy: 0.9745\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.0207 - accuracy: 0.9947 - val_loss: 0.1028 - val_accuracy: 0.9748\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.0191 - accuracy: 0.9952 - val_loss: 0.1041 - val_accuracy: 0.9753\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9958 - val_loss: 0.1027 - val_accuracy: 0.9747\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0159 - accuracy: 0.9965 - val_loss: 0.1063 - val_accuracy: 0.9752\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 0.1067 - val_accuracy: 0.9736\n",
            "Best epoch: 18\n",
            "Epoch 1/21\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3815 - accuracy: 0.8975\n",
            "Epoch 2/21\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1906 - accuracy: 0.9457\n",
            "Epoch 3/21\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1462 - accuracy: 0.9579\n",
            "Epoch 4/21\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1207 - accuracy: 0.9652\n",
            "Epoch 5/21\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1028 - accuracy: 0.9700\n",
            "Epoch 6/21\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0894 - accuracy: 0.9738\n",
            "Epoch 7/21\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0796 - accuracy: 0.9765\n",
            "Epoch 8/21\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0711 - accuracy: 0.9792\n",
            "Epoch 9/21\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0641 - accuracy: 0.9814\n",
            "Epoch 10/21\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.9830\n",
            "Epoch 11/21\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0530 - accuracy: 0.9845\n",
            "Epoch 12/21\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0482 - accuracy: 0.9862\n",
            "Epoch 13/21\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0444 - accuracy: 0.9875\n",
            "Epoch 14/21\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0410 - accuracy: 0.9882\n",
            "Epoch 15/21\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0376 - accuracy: 0.9893\n",
            "Epoch 16/21\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9901\n",
            "Epoch 17/21\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0320 - accuracy: 0.9910\n",
            "Epoch 18/21\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.9917\n",
            "Epoch 19/21\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0273 - accuracy: 0.9927\n",
            "Epoch 20/21\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0253 - accuracy: 0.9930\n",
            "Epoch 21/21\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0233 - accuracy: 0.9941\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0817 - accuracy: 0.9762\n",
            "Epoch 1/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.4210 - accuracy: 0.8871 - val_loss: 0.2355 - val_accuracy: 0.9369\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2159 - accuracy: 0.9390 - val_loss: 0.1826 - val_accuracy: 0.9500\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1680 - accuracy: 0.9524 - val_loss: 0.1526 - val_accuracy: 0.9572\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1387 - accuracy: 0.9599 - val_loss: 0.1341 - val_accuracy: 0.9626\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.1188 - accuracy: 0.9662 - val_loss: 0.1183 - val_accuracy: 0.9664\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1039 - accuracy: 0.9700 - val_loss: 0.1119 - val_accuracy: 0.9694\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0919 - accuracy: 0.9736 - val_loss: 0.1080 - val_accuracy: 0.9693\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0828 - accuracy: 0.9758 - val_loss: 0.1043 - val_accuracy: 0.9702\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0748 - accuracy: 0.9789 - val_loss: 0.1011 - val_accuracy: 0.9717\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.0680 - accuracy: 0.9811 - val_loss: 0.0997 - val_accuracy: 0.9703\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0623 - accuracy: 0.9822 - val_loss: 0.0976 - val_accuracy: 0.9726\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0571 - accuracy: 0.9837 - val_loss: 0.0911 - val_accuracy: 0.9741\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0529 - accuracy: 0.9848 - val_loss: 0.0975 - val_accuracy: 0.9720\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0488 - accuracy: 0.9862 - val_loss: 0.0950 - val_accuracy: 0.9739\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.0448 - accuracy: 0.9878 - val_loss: 0.0945 - val_accuracy: 0.9743\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0420 - accuracy: 0.9883 - val_loss: 0.0934 - val_accuracy: 0.9747\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0388 - accuracy: 0.9895 - val_loss: 0.0927 - val_accuracy: 0.9737\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0360 - accuracy: 0.9901 - val_loss: 0.0938 - val_accuracy: 0.9731\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0329 - accuracy: 0.9912 - val_loss: 0.0955 - val_accuracy: 0.9740\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0306 - accuracy: 0.9916 - val_loss: 0.0917 - val_accuracy: 0.9751\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.9925 - val_loss: 0.0911 - val_accuracy: 0.9752\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 0.0923 - val_accuracy: 0.9744\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0239 - accuracy: 0.9937 - val_loss: 0.0983 - val_accuracy: 0.9742\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0220 - accuracy: 0.9943 - val_loss: 0.0965 - val_accuracy: 0.9734\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0209 - accuracy: 0.9950 - val_loss: 0.0976 - val_accuracy: 0.9749\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 0.0957 - val_accuracy: 0.9756\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.0175 - accuracy: 0.9956 - val_loss: 0.0943 - val_accuracy: 0.9755\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0162 - accuracy: 0.9963 - val_loss: 0.1034 - val_accuracy: 0.9734\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 0.1011 - val_accuracy: 0.9775\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 0.1001 - val_accuracy: 0.9753\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0126 - accuracy: 0.9972 - val_loss: 0.1013 - val_accuracy: 0.9763\n",
            "Best epoch: 21\n",
            "Epoch 1/25\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3887 - accuracy: 0.8959\n",
            "Epoch 2/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1959 - accuracy: 0.9444\n",
            "Epoch 3/25\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1488 - accuracy: 0.9569\n",
            "Epoch 4/25\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1202 - accuracy: 0.9653\n",
            "Epoch 5/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1016 - accuracy: 0.9702\n",
            "Epoch 6/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0887 - accuracy: 0.9737\n",
            "Epoch 7/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0782 - accuracy: 0.9771\n",
            "Epoch 8/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0697 - accuracy: 0.9797\n",
            "Epoch 9/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0634 - accuracy: 0.9813\n",
            "Epoch 10/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0572 - accuracy: 0.9829\n",
            "Epoch 11/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0526 - accuracy: 0.9851\n",
            "Epoch 12/25\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0479 - accuracy: 0.9860\n",
            "Epoch 13/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0443 - accuracy: 0.9874\n",
            "Epoch 14/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0404 - accuracy: 0.9885\n",
            "Epoch 15/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0374 - accuracy: 0.9893\n",
            "Epoch 16/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0349 - accuracy: 0.9899\n",
            "Epoch 17/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.9911\n",
            "Epoch 18/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9918\n",
            "Epoch 19/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0271 - accuracy: 0.9925\n",
            "Epoch 20/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0252 - accuracy: 0.9930\n",
            "Epoch 21/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0233 - accuracy: 0.9938\n",
            "Epoch 22/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0215 - accuracy: 0.9943\n",
            "Epoch 23/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0200 - accuracy: 0.9948\n",
            "Epoch 24/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0182 - accuracy: 0.9955\n",
            "Epoch 25/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0167 - accuracy: 0.9959\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9753\n",
            "Epoch 1/100\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4159 - accuracy: 0.8872 - val_loss: 0.2291 - val_accuracy: 0.9375\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.2181 - accuracy: 0.9377 - val_loss: 0.1746 - val_accuracy: 0.9535\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.1704 - accuracy: 0.9516 - val_loss: 0.1508 - val_accuracy: 0.9584\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1406 - accuracy: 0.9596 - val_loss: 0.1299 - val_accuracy: 0.9636\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.1192 - accuracy: 0.9651 - val_loss: 0.1194 - val_accuracy: 0.9675\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.1039 - accuracy: 0.9694 - val_loss: 0.1116 - val_accuracy: 0.9692\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0918 - accuracy: 0.9727 - val_loss: 0.1069 - val_accuracy: 0.9693\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.0824 - accuracy: 0.9760 - val_loss: 0.1104 - val_accuracy: 0.9675\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0744 - accuracy: 0.9786 - val_loss: 0.0982 - val_accuracy: 0.9708\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.0668 - accuracy: 0.9809 - val_loss: 0.0932 - val_accuracy: 0.9721\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0606 - accuracy: 0.9827 - val_loss: 0.0911 - val_accuracy: 0.9741\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0555 - accuracy: 0.9844 - val_loss: 0.0917 - val_accuracy: 0.9733\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0506 - accuracy: 0.9857 - val_loss: 0.0877 - val_accuracy: 0.9753\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0461 - accuracy: 0.9876 - val_loss: 0.0872 - val_accuracy: 0.9748\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0425 - accuracy: 0.9878 - val_loss: 0.0886 - val_accuracy: 0.9741\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0392 - accuracy: 0.9890 - val_loss: 0.0868 - val_accuracy: 0.9756\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0363 - accuracy: 0.9899 - val_loss: 0.0887 - val_accuracy: 0.9756\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.0333 - accuracy: 0.9908 - val_loss: 0.0871 - val_accuracy: 0.9739\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0303 - accuracy: 0.9916 - val_loss: 0.0897 - val_accuracy: 0.9755\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0285 - accuracy: 0.9922 - val_loss: 0.0891 - val_accuracy: 0.9753\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0259 - accuracy: 0.9932 - val_loss: 0.0897 - val_accuracy: 0.9761\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0238 - accuracy: 0.9940 - val_loss: 0.0867 - val_accuracy: 0.9768\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 0.0914 - val_accuracy: 0.9755\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0197 - accuracy: 0.9951 - val_loss: 0.0891 - val_accuracy: 0.9767\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.0925 - val_accuracy: 0.9750\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0169 - accuracy: 0.9961 - val_loss: 0.0894 - val_accuracy: 0.9767\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0152 - accuracy: 0.9965 - val_loss: 0.0930 - val_accuracy: 0.9771\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.0937 - val_accuracy: 0.9770\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.0127 - accuracy: 0.9971 - val_loss: 0.1015 - val_accuracy: 0.9759\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.0122 - accuracy: 0.9973 - val_loss: 0.0952 - val_accuracy: 0.9759\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.0984 - val_accuracy: 0.9763\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 0.0986 - val_accuracy: 0.9765\n",
            "Best epoch: 22\n",
            "Epoch 1/26\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4005 - accuracy: 0.8923\n",
            "Epoch 2/26\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2038 - accuracy: 0.9427\n",
            "Epoch 3/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1532 - accuracy: 0.9567\n",
            "Epoch 4/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1242 - accuracy: 0.9653\n",
            "Epoch 5/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1045 - accuracy: 0.9700\n",
            "Epoch 6/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0909 - accuracy: 0.9738\n",
            "Epoch 7/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0804 - accuracy: 0.9763\n",
            "Epoch 8/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0715 - accuracy: 0.9791\n",
            "Epoch 9/26\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0648 - accuracy: 0.9815\n",
            "Epoch 10/26\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0590 - accuracy: 0.9826\n",
            "Epoch 11/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9843\n",
            "Epoch 12/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0494 - accuracy: 0.9854\n",
            "Epoch 13/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0453 - accuracy: 0.9873\n",
            "Epoch 14/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0418 - accuracy: 0.9879\n",
            "Epoch 15/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9890\n",
            "Epoch 16/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0352 - accuracy: 0.9900\n",
            "Epoch 17/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0331 - accuracy: 0.9906\n",
            "Epoch 18/26\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0306 - accuracy: 0.9915\n",
            "Epoch 19/26\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0280 - accuracy: 0.9921\n",
            "Epoch 20/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0259 - accuracy: 0.9929\n",
            "Epoch 21/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0240 - accuracy: 0.9938\n",
            "Epoch 22/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0226 - accuracy: 0.9945\n",
            "Epoch 23/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0207 - accuracy: 0.9946\n",
            "Epoch 24/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0194 - accuracy: 0.9952\n",
            "Epoch 25/26\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.9956\n",
            "Epoch 26/26\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0162 - accuracy: 0.9962\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0887 - accuracy: 0.9756\n",
            "Epoch 1/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.4200 - accuracy: 0.8879 - val_loss: 0.2329 - val_accuracy: 0.9353\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.2206 - accuracy: 0.9368 - val_loss: 0.1806 - val_accuracy: 0.9504\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1705 - accuracy: 0.9500 - val_loss: 0.1535 - val_accuracy: 0.9563\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1395 - accuracy: 0.9597 - val_loss: 0.1338 - val_accuracy: 0.9620\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.1178 - accuracy: 0.9649 - val_loss: 0.1260 - val_accuracy: 0.9643\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1027 - accuracy: 0.9702 - val_loss: 0.1157 - val_accuracy: 0.9663\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0907 - accuracy: 0.9740 - val_loss: 0.1069 - val_accuracy: 0.9698\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0802 - accuracy: 0.9773 - val_loss: 0.1072 - val_accuracy: 0.9697\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0724 - accuracy: 0.9792 - val_loss: 0.1099 - val_accuracy: 0.9696\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0657 - accuracy: 0.9808 - val_loss: 0.1013 - val_accuracy: 0.9708\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0600 - accuracy: 0.9822 - val_loss: 0.1016 - val_accuracy: 0.9718\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0549 - accuracy: 0.9843 - val_loss: 0.0964 - val_accuracy: 0.9714\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0503 - accuracy: 0.9859 - val_loss: 0.0972 - val_accuracy: 0.9727\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0461 - accuracy: 0.9873 - val_loss: 0.0928 - val_accuracy: 0.9726\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0423 - accuracy: 0.9883 - val_loss: 0.0935 - val_accuracy: 0.9732\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.0390 - accuracy: 0.9892 - val_loss: 0.0981 - val_accuracy: 0.9726\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.0363 - accuracy: 0.9898 - val_loss: 0.1016 - val_accuracy: 0.9732\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9906 - val_loss: 0.0966 - val_accuracy: 0.9738\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0313 - accuracy: 0.9919 - val_loss: 0.0985 - val_accuracy: 0.9731\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9922 - val_loss: 0.0965 - val_accuracy: 0.9744\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.0266 - accuracy: 0.9934 - val_loss: 0.1028 - val_accuracy: 0.9713\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0247 - accuracy: 0.9937 - val_loss: 0.0967 - val_accuracy: 0.9728\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.0228 - accuracy: 0.9944 - val_loss: 0.0994 - val_accuracy: 0.9739\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0211 - accuracy: 0.9946 - val_loss: 0.1004 - val_accuracy: 0.9738\n",
            "Best epoch: 14\n",
            "Epoch 1/16\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3983 - accuracy: 0.8916\n",
            "Epoch 2/16\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2040 - accuracy: 0.9421\n",
            "Epoch 3/16\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1563 - accuracy: 0.9552\n",
            "Epoch 4/16\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1276 - accuracy: 0.9629\n",
            "Epoch 5/16\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1080 - accuracy: 0.9680\n",
            "Epoch 6/16\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0936 - accuracy: 0.9730\n",
            "Epoch 7/16\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0824 - accuracy: 0.9762\n",
            "Epoch 8/16\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0728 - accuracy: 0.9786\n",
            "Epoch 9/16\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0651 - accuracy: 0.9811\n",
            "Epoch 10/16\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0587 - accuracy: 0.9826\n",
            "Epoch 11/16\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0533 - accuracy: 0.9847\n",
            "Epoch 12/16\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0487 - accuracy: 0.9860\n",
            "Epoch 13/16\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0442 - accuracy: 0.9870\n",
            "Epoch 14/16\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0405 - accuracy: 0.9882\n",
            "Epoch 15/16\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0373 - accuracy: 0.9892\n",
            "Epoch 16/16\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0344 - accuracy: 0.9907\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0840 - accuracy: 0.9770\n"
          ]
        }
      ],
      "source": [
        "def get_best_trained_model(hp):\n",
        "    best_epoch = get_best_epoch(hp)\n",
        "    model = build_model(hp)\n",
        "    model.fit(\n",
        "        x_train_full, y_train_full,\n",
        "        batch_size=128, epochs=int(best_epoch * 1.2))\n",
        "    return model\n",
        "\n",
        "best_models = []\n",
        "for hp in best_hps:\n",
        "    model = get_best_trained_model(hp)\n",
        "    model.evaluate(x_test, y_test)\n",
        "    best_models.append(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that if you're not worried about slightly underperforming, there's a shortcut you can take: just <font color='blue'>use the tuner</font> to <font color='blue'>reload the top-performing models</font> with the <font color='blue'>best weights</font> saved during the hyperparameter search, without retraining new models from scratch:"
      ],
      "metadata": {
        "id": "WUw4gRa9LYMN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RT4JTcujC_mY",
        "outputId": "e5c4a11e-3467-4d66-ea74-71671ea18d99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 5s 14ms/step - loss: 0.0830 - accuracy: 0.9772\n",
            "[0.08303790539503098, 0.9771999716758728]\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0841 - accuracy: 0.9768\n",
            "[0.0840606540441513, 0.9768000245094299]\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.0884 - accuracy: 0.9751\n",
            "[0.08838500827550888, 0.9750999808311462]\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0879 - accuracy: 0.9738\n",
            "[0.08788144588470459, 0.973800003528595]\n"
          ]
        }
      ],
      "source": [
        "best_models = tuner.get_best_models(top_n)\n",
        "\n",
        "# Create a checkpoint with write()\n",
        "ckpt = tf.train.Checkpoint(v=tf.Variable(1.))\n",
        "path = ckpt.write('/tmp/my_checkpoint')\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(model)\n",
        "checkpoint.restore(path).expect_partial()\n",
        "\n",
        "for model in best_models:\n",
        "  print(model.evaluate(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remark:** One  important  issue  to  think  about  when  doing  automatic  hyperparameter  optimization  at  scale  is  <font color='blue'>validation-set  overfitting</font>.  Because  you're updating hyperparameters based on a signal that is computed using your validation data, you're effectively <font color='blue'>training them on the validation data</font>, and thus they will <font color='blue'>quickly overfit</font> to the validation data. Always keep this in mind."
      ],
      "metadata": {
        "id": "NX8O2LFsLfu8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEjh2TQSC_mY"
      },
      "source": [
        "#### The art of crafting the right search space"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, <font color='blue'>hyperparameter  optimization</font> is  a  powerful  technique  that  is  an  absolute requirement for getting to state-of-the-art models on any task or to <font color='blue'>win machine learning competitions</font>. Think about it: once upon a time, people handcrafted the features that  went  into  shallow  machine  learning  models.  That  was  very  much  suboptimal. Now, deep learning <font color='blue'>automates</font> the task of <font color='blue'>hierarchical feature engineering</font>—features are learned using a feedback signal, not hand-tuned, and that's the way it should be. In the same way, you shouldn't handcraft your model architectures; you should optimize them in a principled way.\n",
        "\n",
        "However, doing hyperparameter tuning is <font color='blue'>not a replacement</font> for being familiar\n",
        "with <font color='blue'>model architecture best practices</font>. <font color='blue'>Search spaces grow combinatorially</font> with the number of choices, so it would be far too expensive to turn everything into a hyperparameter  and  let  the  tuner  sort  it  out.  You  need  to  be  smart  about  designing  the right  search  space. Hyperparameter  tuning is  automation,  not  magic:  you  use it to automate  experiments  that  you  would  otherwise  have  run  by  hand,  but  you  still need  to  handpick  experiment  configurations  that  have  the  potential  to  yield  good metrics.\n",
        "\n",
        "The  good  news  is  that  by  <font color='blue'>leveraging  hyperparameter  tuning</font>,  the  configuration decisions you have to make graduate from <font color='blue'>micro-decisions</font> (what number of units do I pick for this layer?) to <font color='blue'>higher-level architecture decisions</font> (should I use residual connections throughout this model?). And while micro-decisions are specific to a certain model and a certain dataset, higher-level decisions generalize better across different tasks  and  datasets.  For  instance,  pretty  much  every  <font color='blue'>image  classification  problem</font> can be solved via the <font color='blue'>same sort of search-space template</font>.\n",
        "\n",
        "Following this logic, <font color='blue'>KerasTuner</font> attempts to <font color='blue'>provide premade search spaces</font> that are relevant to <font color='blue'>broad categories of problems</font>, such as image classification. Just add data, run the search, and get a pretty good model. You can try the hypermodels `kt.applications.HyperXception` and `kt.applications.HyperResNet`,  which are effectively tunable versions of Keras Applications models."
      ],
      "metadata": {
        "id": "NWSczj4GLs6f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po5d5wGDC_mY"
      },
      "source": [
        "#### The future of hyperparameter tuning: automated machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently, most of your job as a deep learning engineer consists of <font color='blue'>munging data with Python scripts</font> and then <font color='blue'>tuning the architecture and hyperparameters</font> of a deep network at length to get a working model, or even to get a state-of-the-art model, if you are  that  ambitious.  Needless  to  say,  that  isn't  an  optimal  setup.  But  automation  can help, and it won't stop merely at hyperparameter tuning.\n",
        "\n",
        "Searching over a set of possible learning rates or possible layer sizes is just the first step. We can also be far <font color='blue'>more ambitious</font> and attempt to <font color='blue'>generate the model architecture itself from scratch</font>, with as few constraints as possible, such as <font color='blue'>via reinforcement learning</font> or <font color='blue'>genetic algorithms</font>. In the future, <font color='blue'>entire end-to-end machine learning pipelines</font> will be <font color='blue'>automatically generated</font>, rather than be handcrafted by engineer-artisans. This is called automated machine learning, or <font color='blue'>AutoML</font>. You can already leverage libraries like  AutoKeras  (https://github.com/keras-team/autokeras) to solve basic machine learning problems with very little involvement on your part.\n",
        "\n",
        "Today, AutoML  is  still in its  early  days,  and  it  doesn't  scale to  large  problems.  But when AutoML becomes mature enough for widespread adoption, the jobs of machine learning engineers won't disappear—rather, engineers will move up the value-creation chain. They will begin to put much more effort into data curation, crafting complex loss functions  that  truly  reflect  business  goals,  as  well  as  understanding  how  their  models\n",
        "impact the digital ecosystems in which they're deployed (such as the users who consume the model's predictions and generate the model's training data). These are problems that only the largest companies can afford to consider at present.\n",
        "\n",
        "Always look at the big picture, focus on understanding the fundamentals, and keep in mind that the <font color='blue'>highly specialized tedium will eventually be automated away</font>. See it as a gift—greater productivity for your workflows—and not as a threat to your own relevance. It shouldn't be your job to tune knobs endlessly."
      ],
      "metadata": {
        "id": "Zl4u7P0TMb_d"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x92p8pT2C_mY"
      },
      "source": [
        "### Model ensembling"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another powerful technique for obtaining the best possible results on a task is <font color='blue'>model ensembling</font>. Ensembling consists of <font color='blue'>pooling together</font> the predictions of a <font color='blue'>set of different  models</font>  to  produce <font color='blue'>better  predictions</font>.  If  you  look  at  machine  learning  competitions, in particular on Kaggle, you'll see that the winners use very <font color='blue'>large ensembles of models</font> that inevitably beat any single model, no matter how good.\n",
        "\n",
        "<font color='blue'>Ensembling</font>  relies  on  the  assumption  that  <font color='blue'>different  well-performing  models</font> trained independently are likely to be good for <font color='blue'>different reasons</font>: each model looks at slightly different aspects of the data to make its predictions, getting part of the \"truth\" but not all of it. You may be familiar with the ancient parable of the blind men and the elephant: a group of blind men come across an elephant for the first time and try to understand what the elephant is by touching it. Each man touches a different part of the elephant's body—just one part, such as the trunk or a leg. Then the men describe\n",
        "to each other what an elephant is: \"It's like a snake,\" \"Like a pillar or a tree,\" and so on. The blind men are essentially machine learning models trying to understand the manifold  of  the  training  data,  each  from  their  own  perspective,  using  their  own assumptions (provided by the unique architecture of the model and the unique random weight initialization). Each of them gets <font color='blue'>part of the truth</font> of the data, but <font color='blue'>not the whole truth</font>. By <font color='blue'>pooling</font> their perspectives together, you can get a <font color='blue'>far more accurate description of the data</font>. The elephant is a combination of parts: not any single blind man gets it quite right, but, interviewed together, they can tell a fairly accurate story.\n",
        "\n",
        "Let's use classification as an example. The easiest way to pool the predictions of a set of classifiers (to *ensemble the classifiers*) is to <font color='blue'>average their predictions</font> at inference time:"
      ],
      "metadata": {
        "id": "BVmIR-13NLFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Psuedocode\n",
        "preds_a = model_a.predict(x_val)                                                # Use four different models to compute initial predictions.\n",
        "preds_b = model_b.predict(x_val)\n",
        "preds_c = model_c.predict(x_val)\n",
        "preds_d = model_d.predict(x_val)\n",
        "final_preds = 0.25 * (preds_a + preds_b + preds_c + preds_d)                    # This new prediction array should be more accurate than any of the initial ones."
      ],
      "metadata": {
        "id": "bLhw7c7nN5Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, this will <font color='blue'>only work</font> if the <font color='blue'>classifiers</font> are <font color='blue'>more or less equally good</font>. If one of them is significantly worse than the others, the final predictions may not be as good as the best classifier of the group.\n",
        "\n",
        "A  smarter  way  to  ensemble  classifiers  is  to  do  a  <font color='blue'>weighted  average</font>,  where  the weights are learned on the validation data—typically, the better classifiers are given a higher weight, and the worse classifiers are given a lower weight. To search for a good set of ensembling weights, you can use <font color='blue'>random search</font> or a simple <font color='blue'>optimization algorithm</font>, such as the <font color='blue'>[Nelder-Mead algorithm](https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method)</font>:"
      ],
      "metadata": {
        "id": "Q9bzdkG6OJc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Psuedocode\n",
        "preds_a = model_a.predict(x_val)                                                # Use four different models to compute initial predictions.\n",
        "preds_b = model_b.predict(x_val)\n",
        "preds_c = model_c.predict(x_val)\n",
        "preds_d = model_d.predict(x_val)\n",
        "final_preds = 0.5 * preds_a + 0.25 * preds_b + 0.1 * preds_c + 0.15 * preds_d   # These weights (0.5, 0.25, 0.1, 0.15) are assumed to be learned empirically."
      ],
      "metadata": {
        "id": "Lp0LnxF_OWO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many possible variants: you can do an <font color='blue'>average</font> of an <font color='blue'>exponential of the predictions</font>, for  instance.  In  general,  a  <font color='blue'>simple  weighted  average</font>  with  weights  optimized on the validation data provides a very <font color='blue'>strong baseline</font>.\n",
        "\n",
        "The key to making ensembling work is the <font color='blue'>diversity</font> of the <font color='blue'>set of classifiers</font>. Diversity is strength. If all the blind men only touched the elephant's trunk, they would agree that elephants are like snakes, and they would forever stay ignorant of the truth of the elephant. Diversity is what makes ensembling work. In machine learning terms, if all of your models are <font color='blue'>biased in the same way</font>, your <font color='blue'>ensemble</font> will <font color='blue'>retain this same bias</font>. If your models are <font color='blue'>biased in different ways</font>, the <font color='blue'>biases</font> will <font color='blue'>cancel each other out</font>, and the ensemble will be more robust and more accurate.\n",
        "\n",
        "For this reason, you should ensemble models that are <font color='blue'>as good as possible</font> while being <font color='blue'>as different as possible</font>. This typically means using very <font color='blue'>different architectures</font> or even <font color='blue'>different brands</font> of machine learning approaches. One thing that is largely <font color='blue'>not worth doing</font> is ensembling the <font color='blue'>same network trained several times independently</font>, from different random initializations. If the only difference between your models is their random initialization and the order in which they were exposed to the training data, then your ensemble will be low-diversity and will provide only a tiny improvement over any single model.\n",
        "\n",
        "One  thing  I  have  found  to  work  well  in  practice—but  that  doesn't  generalize  to every problem domain—is using an <font color='blue'>ensemble of tree-based methods</font> (such as random forests  or  gradient-boosted  trees)  and  deep  neural  networks.  In  2014,  Andrey  Kolev and  I  took  fourth  place  in  the  Higgs  Boson  decay  detection  challenge  on  Kaggle (www.kaggle.com/c/higgs-boson) using an ensemble of various tree models and deep neural  networks.  Remarkably,  one  of the  models  in the  ensemble  originated  from  a different method than the others (it was a regularized greedy forest), and it had a significantly worse score than the others. Unsurprisingly, it was assigned a small weight in the ensemble. But to our surprise, it turned out to improve the overall ensemble by a large factor, because it was so different from every other model: it provided information that the other models didn't have access to. That's precisely the <font color='blue'>point of ensembling</font>. It's not so much about how good your best model is; it's about the <font color='blue'>diversity of your set of candidate models</font>."
      ],
      "metadata": {
        "id": "guQ-AqgBOkru"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iCutqOhC_mZ"
      },
      "source": [
        "## Scaling-up model training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall the <font color='blue'>loop of progress</font> concept we introduced in chapter 7: the quality of your ideas is a function of how many refinement cycles they've been through (see figure below). And the <font color='blue'>speed</font> at which you can iterate on an idea is a function of how fast you can set up an experiment, how fast you can run that experiment, and finally, how well you can analyze the resulting data."
      ],
      "metadata": {
        "id": "Ru46D9jcPmIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![loop_of_progress.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "cCOTzL40LlA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you develop your expertise with the Keras API, <font color='blue'>how fast you can code</font> up your deep learning experiments will <font color='blue'>cease to be the bottleneck</font> of this progress cycle. The next bottleneck will become the <font color='blue'>speed at which you can train your models</font>. Fast training infrastructure means that you can get your results back in 10–15 minutes, and hence, that you can go through dozens of iterations every day. <font color='blue'>Faster training</font> directly improves the <font color='blue'>quality</font> of your deep learning solutions.\n",
        "\n",
        "In this section, you'll learn about three ways you can train your models faster:\n",
        "\n",
        "* Mixed-precision training, which you can use even with a single GPU\n",
        "* Training on multiple GPUs\n",
        "* Training on TPUs\n",
        "\n",
        "Let's go."
      ],
      "metadata": {
        "id": "RqBIymZYLi5F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD0RcSp1C_mZ"
      },
      "source": [
        "### Speeding up training on GPU with mixed precision"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if I told you there's a <font color='blue'>simple technique</font> you can use to speed up the training of <font color='blue'>almost any model by up to 3X</font>, basically for <font color='blue'>free</font>? It seems too good to but true, and yet, such a trick does exist. That's <font color='blue'>mixed-precision training</font>. To understand how it works, we first need to take a look at the notion of <font color='blue'>precision</font> in computer science."
      ],
      "metadata": {
        "id": "i6lTxY8_MHIJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y07lfhmC_mZ"
      },
      "source": [
        "#### Understanding floating-point precision"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision is to numbers what resolution is to images. Because computers can only process ones and zeros, <font color='blue'>any number</font> seen by a computer has to be <font color='blue'>encoded</font> as a <font color='blue'>binary string</font>. For instance, you may be familiar with `uint8` integers, which are integers encoded on eight bits: `00000000` represents `0` in `uint8`, and `11111111` represents `255`. To represent integers beyond `255`, you'd need to <font color='blue'>add more bits</font>—eight isn't enough. <font color='blue'>Most integers</font> are stored on `32` bits, with which you can represent signed integers ranging from `-2147483648` to `2147483647`.\n",
        "\n",
        "Floating-point numbers are the same. In mathematics, <font color='blue'>real numbers</font> form a <font color='blue'>continuous axis</font>: there's an <font color='blue'>infinite number</font> of <font color='blue'>points</font> in between any <font color='blue'>two numbers</font>. You can always zoom in on the axis of reals. In <font color='blue'>computer science</font>, this isn't true: there's a <font color='blue'>finite number</font> of intermediate points between <font color='blue'>3 and 4</font>, for instance. How many? Well, it depends on the <font color='blue'>precision</font> you're working with—the <font color='blue'>number of bits</font> you're using to <font color='blue'>store a number</font>. You can only zoom up to a certain resolution.\n",
        "\n",
        "There are three of levels of precision you'd typically use:\n",
        "* Half precision, or `float16`, where numbers are stored on 16 bits\n",
        "* Single precision, or `float32`, where numbers are stored on 32 bits\n",
        "* Double precision, or `float64`, where numbers are stored on 64 bits\n",
        "\n",
        "#### A note on floating-point encoding\n",
        "\n",
        "A <font color='blue'>counterintuitive fact</font> about <font color='blue'>floating-point numbers</font> is that representable numbers are <font color='blue'>not uniformly distributed</font>. <font color='blue'>Larger numbers</font> have <font color='blue'>lower precision</font>: there are the same number of representable values between `2^N` and `2^(N + 1)` as there are between `1` and `2`, for any `N`. That's because floating-point numbers are encoded in <font color='blue'>three parts</font>—the <font color='blue'>sign</font>, the <font color='blue'>significant value</font> (called the <font color='blue'>mantissa</font>), and the <font color='blue'>exponent</font>, in the form\n",
        "\n",
        "$$ \\operatorname{sign} \\times (2 ^{\\operatorname{exponent}- 127}) \\times 1.\\operatorname{mantissa}$$\n",
        "\n",
        "For example, here's how you would encode the closest `float32` value approximating $\\pi$ :"
      ],
      "metadata": {
        "id": "zzKIzxhKMSUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![pi_encoded.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "Kygr6_kOOoCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The way to think about the <font color='blue'>resolution of floating-point numbers</font> is in terms of the <font color='blue'>smallest distance</font> between <font color='blue'>two arbitrary numbers</font> that you'll be able to <font color='blue'>safely process</font>. In single precision, that's around `1e-7`. In double precision, that's around `1e-16`. And in half precision, it's only `1e-3`.\n",
        "\n",
        "Every model you've seen in this book so far used <font color='blue'>single-precision numbers</font>: it stored its state as `float32` weight variables and ran its computations on `float32` inputs. That's <font color='blue'>enough precision</font> to run the <font color='blue'>forward and backwards pass of a model</font> without losing any information—particularly when it comes to small gradient updates (recall that the typical learning rate is `1e-3`, and it's pretty common to see weight updates on the order of `1e-6`).\n",
        "\n",
        "You could also use `float64`, though that would be <font color='blue'>wasteful—operations</font> like <font color='blue'>matrix multiplication</font> or <font color='blue'>addition</font> are <font color='blue'>much more expensive</font> in <font color='blue'>double precision</font>, so you'd be doing twice as much work for no clear benefits. But you could not do the same with `float16` weights and computation; the <font color='blue'>gradient descent process wouldn't run smoothly</font>, since you couldn't represent small gradient updates of around `1e-5` or `1e-6`.\n",
        "\n",
        "You can, however, use a <font color='blue'>hybrid approach</font>: that's what mixed precision is about. The idea is to leverage `16`-bit computations in places where precision isn't an issue, and to work with `32`-bit values in other places to maintain numerical stability. Modern <font color='blue'>GPUs</font> and <font color='blue'>TPUs</font> feature <font color='blue'>specialized hardware</font> that can run `16`-bit operations <font color='blue'>much faster and use less memory</font> than equivalent `32`-bits operations. By using these lower-precision operations whenever possible, you can speed up training on those devices by a significant factor. Meanwhile, by maintaining the precision-sensitive parts of the model in single precision, you can get these benefits without meaningfully impacting model quality.\n",
        "\n",
        "And those benefits are considerable: on <font color='blue'>modern NVIDIA GPUs</font>, <font color='blue'>mixed precision</font> can speed up training by up to `3X`. It's also beneficial when <font color='blue'>training on a TPU</font> (a subject we'll get to in a bit), where it can speed up training by up to `60%`.\n",
        "\n",
        "#### Beware of dtype defaults\n",
        "<font color='blue'>Single precision</font> is the <font color='blue'>default</font> floating-point type throughout <font color='blue'>Keras</font> and <font color='blue'>TensorFlow</font>: any tensor or variable you create will be in `float32` unless you specify otherwise. For <font color='blue'>NumPy</font> arrays, however, the default is <font color='blue'>double precision</font> or `float64`!\n",
        "\n",
        "Converting a default NumPy array to a TensorFlow tensor will result in a `float64` tensor, which may not be what you want:"
      ],
      "metadata": {
        "id": "V1xhTpoBOyyL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpaa2PXMC_mZ",
        "outputId": "d5ab9a2c-bae7-4b19-edb2-1c507aec68a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "np_array = np.zeros((2, 2))\n",
        "tf_tensor = tf.convert_to_tensor(np_array)\n",
        "tf_tensor.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember to be <font color='blue'>explicit</font> about <font color='blue'>data types</font> when converting NumPy arrays:"
      ],
      "metadata": {
        "id": "BZCTAjhMP4OK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35y1iEX8C_ma",
        "outputId": "09c811a7-0c7d-4cf8-fb69-33048ec5423a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.float32"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "np_array = np.zeros((2, 2))\n",
        "tf_tensor = tf.convert_to_tensor(np_array, dtype=\"float32\")\n",
        "tf_tensor.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that when you call the Keras `fit()` method with NumPy data, it will do this conversion for you."
      ],
      "metadata": {
        "id": "pmvwhvwGP-4B"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFdxfmnmC_ma"
      },
      "source": [
        "#### Mixed-precision training in practice"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When training on a GPU, you can turn on mixed precision like this:"
      ],
      "metadata": {
        "id": "eDKZSLKTQEKF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vPwK-5DC_mb",
        "outputId": "107fe769-68df-4eff-9989-9c6edcd8030d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
            "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
            "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typically, <font color='blue'>most</font> of the <font color='blue'>forward pass of the model</font> will be done in `float16` (with the exception of numerically unstable operations like softmax), while the <font color='blue'>weights of the model</font> will be stored and updated in `float32`.\n",
        "\n",
        "Keras layers have a `variable_dtype` and a `compute_dtype` attribute. By default, both of these are set to `float32`. When you turn on <font color='blue'>mixed precision</font>, the `compute_dtype` of most layers switches to `float16`, and those layers will cast their inputs to `float16` and will perform their computations in `float16` (using half-precision copies of the weights). However, since their `variable_dtype` is still `float32`, their weights will be able to receive accurate `float32` updates from the optimizer, as opposed to half-precision updates.\n",
        "\n",
        "Note that <font color='blue'>some operations</font> may be <font color='blue'>numerically unstable</font> in `float16` (in particular, softmax and crossentropy). If you need to <font color='blue'>opt out of mixed precision</font> for a <font color='blue'>specific layer</font>, just pass the argument `dtype=\"float32\"` to the constructor of this layer."
      ],
      "metadata": {
        "id": "zK4XmyvaQHFU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DriZDM-5C_mb"
      },
      "source": [
        "### Multi-GPU training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While GPUs are getting more powerful every year, deep learning models are getting increasingly larger, requiring ever more computational resources. Training on a <font color='blue'>single GPU</font> puts a <font color='blue'>hard bound</font> on how fast you can move. The solution? You could simply <font color='blue'>add more GPUs</font> and start doing <font color='blue'>multi-GPU distributed training</font>.\n",
        "\n",
        "There are two ways to distribute computation across multiple devices: <font color='blue'>data parallelism</font> and <font color='blue'>model parallelism</font>.\n",
        "\n",
        "With data parallelism, a <font color='blue'>single model</font> is <font color='blue'>replicated</font> on <font color='blue'>multiple devices</font> or multiple machines. Each of the model replicas <font color='blue'>processes different batches of data</font>, and then they <font color='blue'>merge</font> their results.\n",
        "\n",
        "With model parallelism, <font color='blue'>different parts</font> of a single <font color='blue'>model</font> run on <font color='blue'>different devices</font>, processing a <font color='blue'>single batch</font> of <font color='blue'>data together</font> at the same time. This works best with models that have a naturally parallel architecture, such as models that feature multiple branches.\n",
        "\n",
        "In practice, <font color='blue'>model parallelism</font> is only used for <font color='blue'>models</font> that are <font color='blue'>too large to fit on any single device</font>: it isn't used as a way to speed up training of regular models, but as a way to <font color='blue'>train larger models</font>. We won't cover model parallelism in these pages; instead we'll focus on what you'll be <font color='blue'>using most</font> of the time: <font color='blue'>data parallelism</font>. Let's take a look at how it works."
      ],
      "metadata": {
        "id": "D48fibXFQzqb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj0r3-XDC_mb"
      },
      "source": [
        "#### Getting your hands on two or more GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, you need to <font color='blue'>get access</font> to <font color='blue'>several GPUs</font>. As of now, Google Colab only lets you use a single GPU, so you will need to do one of two things:\n",
        "\n",
        "* Acquire 2-4 GPUs, mount them on a single machine (it will require a beefy\n",
        "power supply), and install CUDA drivers, cuDNN, etc. For most people, this\n",
        "isn't the best option.\n",
        "* Rent a multi-GPU Virtual Machine (VM) on Google Cloud, Azure, or AWS.\n",
        "You'll be able to use VM images with preinstalled drivers and software, and\n",
        "you'll have very little setup overhead. This is <font color='blue'>likely the best option</font> for anyone who isn't training models 24/7.\n",
        "\n",
        "We won't cover the details of how to spin up multi-GPU cloud VMs, because such instructions would be relatively short-lived, and this information is readily available online.\n",
        "\n",
        "And if you don't want to deal with the overhead of managing your own VM\n",
        "instances, you can use TensorFlow Cloud (https://github.com/tensorflow/cloud), a\n",
        "package that my team and I have recently released—it enables you to start training on multiple GPUs by just adding one line of code at the start of a Colab notebook. If you're looking for a seamless transition from debugging your model in Colab to training it as fast as possible on as many GPUs as you want, check it out."
      ],
      "metadata": {
        "id": "ELYygAqcRNXp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-NaipiSC_mb"
      },
      "source": [
        "#### Single-host, multi-device synchronous training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you're able to import tensorflow on a machine with multiple GPUs, you're seconds away from training a distributed model. It works like this:"
      ],
      "metadata": {
        "id": "GjBxYN87Ruit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()                                     # Create a “distribution strategy” object. MirroredStrategy should be your go-to solution.\n",
        "print(f\"Number of devices: {strategy.num_replicas_in_sync}\")\n",
        "with strategy.scope():                                                          # Use it to open a “strategy scope.”\n",
        "  model = get_compiled_model()                                                  # Everything that creates variables should be under the strategy scope. In general, this is only model construction and compile().\n",
        "model.fit(                                                                      # Train the model on all available devices.\n",
        "  train_dataset,\n",
        "  epochs=100,\n",
        "  validation_data=val_dataset,\n",
        "  callbacks=callbacks)"
      ],
      "metadata": {
        "id": "IFwZeNClR0qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These few lines implement the most common training setup: *single-host*, *multi-device synchronous training*, also known in TensorFlow as the <font color='blue'>mirrored distribution strategy</font>. <font color='blue'>Single host</font> means that the <font color='blue'>different GPUs</font> considered are <font color='blue'>all on a single machine</font> (as opposed to a cluster of many machines, each with its own GPU, communicating over a network). <font color='blue'>Synchronous training</font> means that the <font color='blue'>state of the per-GPU model replicas stays the same</font> at all times—there are variants of distributed training where this isn't the case.\n",
        "\n",
        "When you open a <font color='blue'>MirroredStrategy</font> scope and build your model within it, the <font color='blue'>MirroredStrategy object</font> will create one model copy (replica) on each available GPU.\n",
        "\n",
        "Then, each step of training unfolds in the following way (see figure below):\n",
        "\n",
        "1. A batch of data (called *global batch*) is drawn from the dataset.\n",
        "2. It gets split into four different sub-batches (called *local batches*). For instance, if the global batch has `512` samples, each of the four local batches will have `128` samples. Because you want local batches to be large enough to keep the GPU busy, the global batch size typically needs to be very large.\n",
        "3. Each of the four replicas processes one local batch, independently, on its own device: they run a forward pass, and then a backward pass. Each replica outputs a \"weight delta\" describing by how much to update each weight variable in the model, given the gradient of the previous weights with respect to the loss of the model on the local batch.\n",
        "4. The weight deltas originating from local gradients are efficiently merged across the four replicas to obtain a global delta, which is applied to all replicas. Because this is done at the end of every step, the replicas always stay in sync: their weights are always equal.\n",
        "\n"
      ],
      "metadata": {
        "id": "D73ow-6OSagy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![mirrored_strategy.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "GUIb8TecTf1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `tf.data` performance tips\n",
        "When doing distributed training, always provide your data as a `tf.data.Dataset`\n",
        "object to guarantee best performance. (Passing your data as NumPy arrays also\n",
        "works, since those get converted to Dataset objects by `fit()`). You should also\n",
        "make sure you leverage <font color='blue'>data prefetching</font>: before passing the dataset to `fit()`, call `dataset.prefetch(buffer_size)`. If you aren't sure what buffer size to pick, try the <font color='blue'>`dataset.prefetch(tf.data.AUTOTUNE)`</font> option, which will pick a buffer size for you.\n",
        "\n",
        "In an ideal world, training on $N$ GPUs would result in a speedup of factor $N$. In practice, however, <font color='blue'>distribution</font> introduces <font color='blue'>some overhead</font>—in particular, merging the weight deltas originating from different devices takes some time. The effective speedup you get is a function of the number of GPUs used:\n",
        "\n",
        "* With two GPUs, the speedup stays close to 2x.\n",
        "* With four, the speedup is around 3.8x.\n",
        "* With eight, it's around 7.3x.\n",
        "\n",
        "This assumes that you're using a large enough global batch size to keep each GPU utilized at full capacity. If your batch size is too small, the local batch size won't be enough to keep your GPUs busy."
      ],
      "metadata": {
        "id": "OHx40DViTo3Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDjyQerkC_mb"
      },
      "source": [
        "### TPU training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beyond just GPUs, there is a trend in the deep learning world toward <font color='blue'>moving workflows</font> to increasingly <font color='blue'>specialized hardware</font> designed specifically for <font color='blue'>deep learning workflows</font> (such single-purpose chips are known as ASICs application-specific integrated circuits). Various companies big and small are working on new chips, but today the most prominent effort along these lines is Google's <font color='blue'>Tensor Processing Unit</font> (TPU), which is available on Google Cloud and via Google Colab. Training on a TPU does involve jumping through some hoops, but it's worth the extra work: TPUs are really, really fast. Training on a <font color='blue'>TPU V2</font> will typically be <font color='blue'>15x faster</font> than training an <font color='blue'>NVIDIA P100 GPU</font>. For most models, <font color='blue'>TPU training</font> ends up being <font color='blue'>3x more cost-effective</font> than GPU training on average."
      ],
      "metadata": {
        "id": "wRiAKP4lUPhK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9rufO6_C_mc"
      },
      "source": [
        "#### Using a TPU via Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can actually use an 8-core TPU for free in Colab. In the Colab menu, under the Runtime tab, in the Change Runtime Type option, you'll notice that you have <font color='blue'>access to a TPU runtime</font> in addition to the GPU runtime.\n",
        "\n",
        "When you're using the <font color='blue'>GPU runtime</font>, your models have <font color='blue'>direct access to the GPU</font> without you needing to do anything special. This <font color='blue'>isn't true</font> for the <font color='blue'>TPU runtime</font>; there's an extra step you need to take before you can start building a model: you need to <font color='blue'>connect to the TPU cluster</font>.\n",
        "\n",
        "It works like this:"
      ],
      "metadata": {
        "id": "DIEIiosHUeHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "print(\"Device:\", tpu.master())"
      ],
      "metadata": {
        "id": "a3TyZsjXUo2r",
        "collapsed": true,
        "outputId": "8d0b54fd-eff6-45ee-c006-6a958d21e369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Please provide a TPU Name to connect to.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2a4aa4576845>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Device:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(tpu, zone, project)\u001b[0m\n\u001b[1;32m    143\u001b[0m       \u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mno\u001b[0m \u001b[0mTPU\u001b[0m \u001b[0mdevices\u001b[0m \u001b[0mfound\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meager\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \"\"\"\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mresolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_to_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mtpu_strategy_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_tpu_system_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tpu, zone, project, job_name, coordinator_name, coordinator_address, credentials, service, discovery_url)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtpu\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'local'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0;31m# Default Cloud environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m       self._cloud_tpu_client = client.Client(\n\u001b[0m\u001b[1;32m    236\u001b[0m           \u001b[0mtpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m           \u001b[0mzone\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/tpu/client/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tpu, zone, project, credentials, service, discovery_url)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mzone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtpu_node_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zone'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please provide a TPU Name to connect to.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Please provide a TPU Name to connect to."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You don't have to worry too much about what this does—it's just a little incantation that connects your notebook runtime to the device. Open Sesame.\n",
        "\n",
        "Much like in the case of <font color='blue'>multi-GPU training</font>, using the TPU requires you to <font color='blue'>open a distribution strategy scope</font>—in this case, a `TPUStrategy` scope. `TPUStrategy` follows the same distribution template as `MirroredStrategy`—the model is replicated once per TPU core, and the replicas are kept in sync.\n",
        "\n",
        "Here's a simple example."
      ],
      "metadata": {
        "id": "8XgpXTffUtuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a model in a TPUStrategy scope\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "strategy = tf.distribute.TPUStrategy(tpu)\n",
        "print(f\"Number of replicas: {strategy.num_replicas_in_sync}\")\n",
        "def build_model(input_size):\n",
        "  inputs = keras.Input((input_size, input_size, 3))\n",
        "  x = keras.applications.resnet.preprocess_input(inputs)\n",
        "  x = keras.applications.resnet.ResNet50(\n",
        "    weights=None, include_top=False, pooling=\"max\")(x)\n",
        "  outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  model.compile(optimizer=\"rmsprop\",\n",
        "  loss=\"sparse_categorical_crossentropy\",\n",
        "  metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "with strategy.scope():\n",
        "  model = build_model(input_size=32)"
      ],
      "metadata": {
        "id": "1httFdGrVEtS",
        "collapsed": true,
        "outputId": "e7237143-414a-45b7-c33b-8cc917a5cc2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tpu' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-578f47f7e12c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of replicas: {strategy.num_replicas_in_sync}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tpu' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're almost ready to start training. But there's something a bit curious about <font color='blue'>TPUs in Colab</font>: it's a two-VM setup, meaning that the VM that hosts your notebook runtime isn't the same VM that the TPU lives in. Because of this, you <font color='blue'>won't be able to train from files stored on the local disk</font> (that is to say, on the disk linked to the VM that hosts the notebook). The TPU runtime can't read from there. You have two options for data loading:\n",
        "\n",
        "* Train from data that lives in the memory of the VM (not on disk). If your data is in a NumPy array, this is what you're already doing.\n",
        "* Store the data in a Google Cloud Storage (GCS) bucket, and create a dataset\n",
        "that reads the data directly from the bucket, without downloading locally. The\n",
        "TPU runtime can read data from GCS. This is your only option for datasets that\n",
        "are too large to live entirely in memory.\n",
        "\n",
        "In our case, let's train from NumPy arrays in memory—the CIFAR10 dataset:"
      ],
      "metadata": {
        "id": "kIoJ-uHYVcKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "model.fit(x_train, y_train, batch_size=1024)                                    # Note that TPU training, much like multi-GPU training, requires large batch sizes to\n",
        "                                                                                # make sure the device stays well-utilized."
      ],
      "metadata": {
        "id": "ZQY9obBQVt1E",
        "collapsed": true,
        "outputId": "82d6dcd9-727f-434b-e592-cb02ae2ad2fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 7s 0us/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1b8caaac299b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m                                    \u001b[0;31m# Note that TPU training, much like multi-GPU training, requires large batch sizes to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                                                 \u001b[0;31m# make sure the device stays well-utilized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll notice that the first epoch takes a while to start—that's because your model is getting compiled to something that the TPU can execute. Once that step is done, the training itself is blazing fast.\n",
        "\n",
        "**Beware of I/O bottlenecks**: Because TPUs can process batches of data extremely quickly, the speed at which you can read data from GCS can easily become a bottleneck.\n",
        "\n",
        "* If your dataset is small enough, you should keep it in the memory of the VM.\n",
        "You can do so by calling `dataset.cache()` on your dataset. That way, the\n",
        "data will only be read from GCS once.\n",
        "* If your dataset is too large to fit in memory, make sure to store it as TFRecord files—an efficient binary storage format that can be loaded very quickly. On keras.io, you'll find a code example demonstrating how to format your data as TFRecord files (https://keras.io/examples/keras_recipes/creating_tfrecords/)."
      ],
      "metadata": {
        "id": "JOT6bGRdV8Bj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DBKCzkOC_mc"
      },
      "source": [
        "#### Leveraging step fusing to improve TPU utilization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because a <font color='blue'>TPU</font> has a lot of <font color='blue'>compute power available</font>, you need to train with <font color='blue'>very large batches</font> to keep the TPU cores busy. For small models, the <font color='blue'>batch size</font> required can get <font color='blue'>extraordinarily large</font>—upwards of 10,000 samples per batch. When working with enormous batches, you should make sure to increase your optimizer learning rate accordingly; you're going to be making fewer updates to your weights, but each update will be more accurate (since the gradients are computed using more data points), so you should move the weights by a greater magnitude with each update.\n",
        "\n",
        "There is, however, a simple trick you can leverage to keep reasonably sized batches while maintaining full TPU utilization: <font color='blue'>step fusing</font>. The idea is to run <font color='blue'>multiple steps of training</font> during <font color='blue'>each TPU execution step</font>. Basically, do more work in between two round trips from the VM memory to the TPU. To do this, simply specify the `steps_per_execution` argument in `compile()`—for instance, `steps_per_execution=8` to run eight steps of training during each TPU execution. For small models that are underutilizing the TPU, this can result in a dramatic speedup."
      ],
      "metadata": {
        "id": "_HeGJmkPWSwQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAx2pqqiC_mc"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* You can leverage <font color='blue'>hyperparameter tuning</font> and <font color='blue'>KerasTuner</font> to <font color='blue'>automate the tedium</font> out of finding the <font color='blue'>best model configuration</font>. But be mindful of validation-set overfitting!\n",
        "* An <font color='blue'>ensemble of diverse models</font> can often significantly <font color='blue'>improve</font> the <font color='blue'>quality</font> of your predictions.\n",
        "* You can <font color='blue'>speed up model training</font> on <font color='blue'>GPU</font> by turning on <font color='blue'>mixed precision</font>—\n",
        "you'll generally get a nice speed boost at virtually no cost.\n",
        "* To further scale your workflows, you can use the `tf.distribute.Mirrored-Strategy` API to train models on multiple GPUs.\n",
        "* You can even <font color='blue'>train on Google's TPUs</font> (available on Colab) by using the `TPU-\n",
        "Strategy API`. If your model is small, make sure to leverage step fusing (via the `compile(…, steps_per_execution=N)` argument) in order to fully utilize the TPU cores."
      ],
      "metadata": {
        "id": "uRLoe7jAWrtE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N8EuhpkcW6Mv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "chapter13_best-practices-for-the-real-world.i",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}