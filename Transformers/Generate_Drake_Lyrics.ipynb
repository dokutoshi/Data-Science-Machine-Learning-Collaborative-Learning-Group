{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDbG4g8aSZez"
      },
      "source": [
        "## Welcome to GPT & Chill !\n",
        "\n",
        "# I created this companion notebook to help anyone learning from this set of problems: https://www.gptandchill.ai/codingproblems see their working GPT in action.\n",
        "\n",
        "# I created GPT & Chill to teach Machine Learning without insane math. My website is https://www.gptandchill.ai and my YouTube channel can be found here https://www.youtube.com/@GPTandChill . Happy Coding!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQqKvoi0sN5j"
      },
      "source": [
        "Before running anything, Runtime -> Change Runtime Type -> T4 GPU. This will speed up the results. Just run each cell one by one to generate the Drake lyrics, which uses your exact code from the problem!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q0vw82YZsG6S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1UE_Q_GsYOh"
      },
      "source": [
        "No need to touch the GPT class below. Just run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ji3UY_16sLYy"
      },
      "outputs": [],
      "source": [
        "class GPT(nn.Module):\n",
        "\n",
        "    class TransformerBlock(nn.Module):\n",
        "\n",
        "        class MultiHeadedSelfAttention(nn.Module):\n",
        "\n",
        "            class SingleHeadAttention(nn.Module):\n",
        "                def __init__(self, model_dim: int, head_size: int):\n",
        "                    super().__init__()\n",
        "                    self.key_layer = nn.Linear(model_dim, head_size, bias=False)\n",
        "                    self.query_layer = nn.Linear(model_dim, head_size, bias=False)\n",
        "                    self.value_layer = nn.Linear(model_dim, head_size, bias=False)\n",
        "\n",
        "                def forward(self, embedded):\n",
        "                    k = self.key_layer(embedded)\n",
        "                    q = self.query_layer(embedded)\n",
        "                    v = self.value_layer(embedded)\n",
        "\n",
        "                    scores = q @ torch.transpose(k, 1, 2) # @ is the same as torch.matmul()\n",
        "                    context_length, attention_dim = k.shape[1], k.shape[2]\n",
        "                    scores = scores / (attention_dim ** 0.5)\n",
        "\n",
        "                    lower_triangular = torch.tril(torch.ones(context_length, context_length))\n",
        "                    mask = (lower_triangular == 0).to(device)\n",
        "                    scores = scores.masked_fill(mask, float('-inf'))\n",
        "                    scores = nn.functional.softmax(scores, dim = 2)\n",
        "\n",
        "                    return scores @ v\n",
        "\n",
        "            def __init__(self, model_dim: int, num_heads: int):\n",
        "                super().__init__()\n",
        "                self.attention_heads = nn.ModuleList()\n",
        "                for i in range(num_heads):\n",
        "                    self.attention_heads.append(self.SingleHeadAttention(model_dim, model_dim // num_heads))\n",
        "                self.compute = nn.Linear(model_dim, model_dim)\n",
        "                self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "            def forward(self, embedded):\n",
        "                head_outputs = []\n",
        "                for head in self.attention_heads:\n",
        "                    head_outputs.append(head(embedded))\n",
        "                concatenated = torch.cat(head_outputs, dim = 2)\n",
        "                return self.dropout(self.compute(concatenated))\n",
        "\n",
        "        class VanillaNeuralNetwork(nn.Module):\n",
        "\n",
        "            def __init__(self, model_dim: int):\n",
        "                super().__init__()\n",
        "                self.first_linear_layer = nn.Linear(model_dim, model_dim * 4)\n",
        "                self.relu = nn.ReLU()\n",
        "                self.second_linear_layer = nn.Linear(model_dim * 4, model_dim)\n",
        "                self.dropout = nn.Dropout(0.2) # using p = 0.2\n",
        "\n",
        "            def forward(self, x):\n",
        "                return self.dropout(self.second_linear_layer(self.relu(self.first_linear_layer(x))))\n",
        "\n",
        "        def __init__(self, model_dim: int, num_heads: int):\n",
        "            super().__init__()\n",
        "            self.mhsa = self.MultiHeadedSelfAttention(model_dim, num_heads)\n",
        "            self.vanilla_nn = self.VanillaNeuralNetwork(model_dim)\n",
        "            self.layer_norm_one = nn.LayerNorm(model_dim)\n",
        "            self.layer_norm_two = nn.LayerNorm(model_dim)\n",
        "\n",
        "        def forward(self, embedded):\n",
        "            embedded = embedded + self.mhsa(self.layer_norm_one(embedded)) # skip connection\n",
        "            embedded = embedded + self.vanilla_nn(self.layer_norm_two(embedded)) # another skip connection\n",
        "            return embedded\n",
        "\n",
        "    def __init__(self, vocab_size: int, context_length: int, model_dim: int, num_blocks: int, num_heads: int):\n",
        "        super().__init__()\n",
        "        self.token_embedding = nn.Embedding(vocab_size, model_dim)\n",
        "        self.pos_embedding = nn.Embedding(context_length, model_dim)\n",
        "        self.transformer_blocks = nn.Sequential()\n",
        "        for i in range(num_blocks):\n",
        "            self.transformer_blocks.append(self.TransformerBlock(model_dim, num_heads))\n",
        "        self.layer_norm_three = nn.LayerNorm(model_dim)\n",
        "        self.vocab_projection = nn.Linear(model_dim, vocab_size)\n",
        "\n",
        "    def forward(self, context):\n",
        "        embedded = self.token_embedding(context)\n",
        "        context_length = context.shape[1]\n",
        "        positions = torch.arange(context_length).to(device)\n",
        "        embedded = embedded + self.pos_embedding(positions)\n",
        "\n",
        "        raw_output = self.vocab_projection(self.layer_norm_three(self.transformer_blocks(embedded)))\n",
        "        # raw_output is batch by context_length by vocab_size\n",
        "\n",
        "        return raw_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMHYCe-SseQl"
      },
      "source": [
        "Your generate() function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-x9xWrUAsbdC"
      },
      "outputs": [],
      "source": [
        "def generate(model, new_chars: int, context, context_length: int, int_to_char: dict) -> str:\n",
        "    res = []\n",
        "    for i in range(new_chars):\n",
        "        if len(context.T) > context_length:\n",
        "            context = context[:, -context_length:]\n",
        "        prediction = model(context) # B, T, Vocab_Size\n",
        "        last_time_step = prediction[:, -1, :] # B, Vocab_Size\n",
        "        probabilities = nn.functional.softmax(last_time_step, dim = -1)\n",
        "        next_char = torch.multinomial(probabilities, 1)\n",
        "        context = torch.cat((context, next_char), dim = -1)\n",
        "        res.append(int_to_char[next_char.item()])\n",
        "    return ''.join(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX6JVta_tuCm"
      },
      "source": [
        "Let's download the trained model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8wDHQmot0M2",
        "outputId": "55107527-c2c8-46fb-d072-530b0faa7f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'drake-lyric-generator'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (3/3), 16.53 MiB | 14.94 MiB/s, done.\n",
            "/content/drake-lyric-generator\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/gptandchill/drake-lyric-generator\n",
        "%cd drake-lyric-generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckqEPmJUsnfF"
      },
      "source": [
        "Define the hyperparameters, instantiate the model, and load in the weights from training. The prior cell downloads weights.pt into this Colab runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aBPCi79SskEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a784aed-c0ff-4bbe-adc2-586315408be6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-62092e9632fa>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(WEIGHT_PATH, map_location=torch.device('cpu')))\n"
          ]
        }
      ],
      "source": [
        "vocab_size = 104\n",
        "context_length = 128\n",
        "model_dim = 252\n",
        "num_blocks = 6\n",
        "num_heads = 6\n",
        "\n",
        "model = GPT(vocab_size, context_length, model_dim, num_blocks, num_heads).to(device)\n",
        "WEIGHT_PATH = 'weights.pt' # Adjust as necessary\n",
        "#model.load_state_dict(torch.load(WEIGHT_PATH))\n",
        "# Load the model weights onto the CPU\n",
        "model.load_state_dict(torch.load(WEIGHT_PATH, map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "new_chars = 5000\n",
        "context = torch.zeros(1, 1, dtype = torch.int64).to(device)\n",
        "\n",
        "int_to_char = {0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '$', 5: '%', 6: '&', 7: \"'\", 8: '(', 9: ')', 10: '*', 11: '+', 12: ',', 13: '-', 14: '.', 15: '/', 16: '0', 17: '1', 18: '2', 19: '3', 20: '4', 21: '5', 22: '6', 23: '7', 24: '8', 25: '9', 26: ':', 27: ';', 28: '?', 29: 'A', 30: 'B', 31: 'C', 32: 'D', 33: 'E', 34: 'F', 35: 'G', 36: 'H', 37: 'I', 38: 'J', 39: 'K', 40: 'L', 41: 'M', 42: 'N', 43: 'O', 44: 'P', 45: 'Q', 46: 'R', 47: 'S', 48: 'T', 49: 'U', 50: 'V', 51: 'W', 52: 'X', 53: 'Y', 54: 'Z', 55: '[', 56: ']', 57: '_', 58: 'a', 59: 'b', 60: 'c', 61: 'd', 62: 'e', 63: 'f', 64: 'g', 65: 'h', 66: 'i', 67: 'j', 68: 'k', 69: 'l', 70: 'm', 71: 'n', 72: 'o', 73: 'p', 74: 'q', 75: 'r', 76: 's', 77: 't', 78: 'u', 79: 'v', 80: 'w', 81: 'x', 82: 'y', 83: 'z', 84: '{', 85: '|', 86: '}', 87: 'à', 88: 'á', 89: 'è', 90: 'é', 91: 'ë', 92: 'ñ', 93: 'ó', 94: 'ú', 95: '\\u2005', 96: '–', 97: '—', 98: '‘', 99: '’', 100: '“', 101: '”', 102: '…', 103: '\\u205f'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmYfLP60tPrS"
      },
      "source": [
        "Run the below cell over and over again to get new lyrics!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpwXg0YitK0w",
        "outputId": "83990157-f651-43bd-ee09-b066752ab13e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Bout just to be finure, and no good no cane\n",
            "My next man, no steady's aways got got relige\n",
            "I sany back up in the couple like this one girls only missication\n",
            "All if \"\"Well perrabled, tryna get it unpranded\n",
            "You know what I'm tryna say I'm takin' a prizzice I'll actin'\n",
            "And I'm so I'ma like a fuck\n",
            "Drake I'm higher a east like to shelk way like the bloch Mordalina\n",
            "You how I came at like a upine\n",
            "Same in the walk of the rappertionity time\n",
            "But Gunnia dogies in a tryna call\n",
            "How she's sand the stories that I've gotta make mode\n",
            "Goin' man, sleep alridion, you wante tches you desare\n",
            "\n",
            "[Drake]\n",
            "Someone sometimes like \"\"Hey whome promise, special week like Grewzy\n",
            "Hen only do maybe diebown't the still terO\n",
            "Bitch, youou got and went too much to hurt\n",
            "Your stuck but I'm person\n",
            "You just roll bill positing to filly phone love like the world's\n",
            "Five if I'm gone (Long, done), you we gon' got this street other 6 man, and Like you're Miched Lah (Ugh\n",
            "Yo, yeah)\n",
            "\n",
            "[Verse 3: Katn Drake]\n",
            "Took oner luguis alonight\n",
            "You the forthat is homie\n",
            "Cause in them boy for you that I love you\n",
            "Fuck on me on the streets, let lost\n",
            "I always changed, man, I got you celebration\n",
            "You gotta heart bobby one for your girl?\n",
            "I showl you might brought talkin' when you show up\n",
            "(She just you like to date where I get you\"\n",
            "\"[Chorus]\n",
            "Now she find show in the mouth (Fuck knew)\n",
            "Got my own, ayou know the same 'cause I'm a showce, baby, byes I'm in the ones home\n",
            "One life time one 'omeone we dieboesn't colin'\n",
            "But it's just sweople out the good doo–\n",
            "Nebbin' the world on girl, we long 'cause, we up in my pull\n",
            "\n",
            "[Verse 1: Drake]\n",
            "We got a hot, Verse Parcorrey, no morra, saskin'\n",
            "Stuck say night, my now nigStuck in Belaces Frang, heiths on None I'm Phhenecialled\n",
            "Y'Ca body switch is supposed of Gincestant\n",
            "Infect like that\n",
            "She counter privicta scars up in the fact\n",
            "Sex as for nicial are back I'm talkin' wishin'\n",
            "The tinnerst for me with the trubbstmant for your elselse\n",
            "(You gotta truck sold, the only that's in my money, we gon' got?)\n",
            "You leave I need probably in your head and long girl's only cerbucher man\n",
            "But I ain't camn, what's changed\n",
            "Oh, you give you know, huh?\n",
            "I be get your more for you\"\"\n",
            "Who is steaded, what's up brooms and as it good the niggas ro: & Hotiol Norrie (Max)\n",
            "From the problege and comfolic we hard and tell know some down (Mo!)\n",
            "Yeah\n",
            "You niggas hot some glik+ Kick (Money)\n",
            "I take my taki, enouse\n",
            "Steale got hold so I got 'em like Paura Dica\n",
            "You got me here the knocks, know I because I've been tour mornin'\n",
            "I'm way too, too kill got someone comin' over attention\n",
            "So gonna say show \"\"took chack out?\"\"\n",
            "\"[Intro]\"\" on my life\"\"\n",
            "\"[Intro]\n",
            "Got zone of of been\n",
            "\n",
            "[Produced by To Songz]\n",
            "Make it a jendoin', I tell you I got surrores\n",
            "Please, \"\"Windorworkers, and 3make The Ranamilian\n",
            "The Tostrey girls and there everyonrion\n",
            "I can decial place Treyal Wine\n",
            "When Was like Maristied Viramons\n",
            "Crisz BMB and Swizz in the cludic, with it worlds, The ream\n",
            "Like up 40 is and Mobody win' around yes\n",
            "Bitconed on and then you women soon my way from\n",
            "You chance wouldn’t you even knew\n",
            "The talkin' is for it, but I knock the orRook when you nother like the sells, Songz tonight man\n",
            "So I just wanna\n",
            "And I'm out the of lost, with it with you\n",
            "(It's a down)\n",
            "\n",
            "[Refrain: DJ Pole]\n",
            "With Caso\n",
            "Woundin' be night need I was and the hand to know I walk\n",
            "Now it's fuckin' my store off in a Crazy\n",
            "Mition without yeah, now you're reminuted to started\n",
            "Any you half and get like lookin' 'cause you're not your broker ones\n",
            "So he say faded up at like I'm stin' you, I'm loned Kapleys\n",
            "Beat when I can't steak\n",
            "I'd got cool, you clot in like the night scripted\n",
            "No in perpewitzitions\n",
            "And so I was like chall classie\n",
            "Yeah, oh, the knook whoat she said, I got no so ine\n",
            "Got a good, I'm goin' one it, that's just they want to be\n",
            "People that tryna tell there gratession, they drive is?\n",
            "\n",
            "[Verse 1]\n",
            "I was fucking your heels sayings your Dairake It's robeleed\n",
            "Weekeny thinkin', don't make it\n",
            "I’m goin' looking, I knew I say I'm sofickely\n",
            "You ain’t need to the same, I'm already do who was it, I only only believe Pain\n",
            "Then we leep alonely\n",
            "\n",
            "[Post-Chorus]\n",
            "What the neight I'm about to what's when\n",
            "I'm too long, I'm after here\n",
            "I'm heatin', they die\n",
            "I swear you\n",
            "I'm as and sometimes you find without for all this facest, man?\n",
            "It's cause I'll take it how to show I were it\n",
            "We walkin' diffendy tour comin' a story (Hah)\n",
            "I'll ever still\n",
            "Summer of night closer go\n",
            "I would this only one get real one emiration\n",
            "Make the other swag him later one it\n",
            "Everybody day, I need it, I got don't a histenning, why you need this postant\n",
            "That's just that hate me when you stuck by\n",
            "\n",
            "[Verse 1]\n",
            "Hot out a 6 Go\n",
            "My people smotto the rough\n",
            "My life senders like /A44\n",
            "Shance I don't even groupe of when I deeper people that\n",
            "You plus your shoot are of your broudes\n",
            "The fitch: Derain the enthrough, shit\n",
            "And we're back I'm so I'm so takin' to the table shit\n",
            "So look on the team, yeah, stop went in eading\n",
            "Saround]\n",
            "You've been me call through (Bring up to tick it\n",
            "You women get up, home old your one tine and I ne\n"
          ]
        }
      ],
      "source": [
        "print(generate(model, new_chars,context,\n",
        "               context_length,\n",
        "               int_to_char))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}